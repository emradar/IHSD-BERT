{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 10167,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014753614635585718,
      "grad_norm": 45.20372772216797,
      "learning_rate": 1.9930658011212748e-05,
      "loss": 0.5115,
      "step": 50
    },
    {
      "epoch": 0.029507229271171435,
      "grad_norm": 31.487777709960938,
      "learning_rate": 1.985836529949838e-05,
      "loss": 0.4032,
      "step": 100
    },
    {
      "epoch": 0.04426084390675716,
      "grad_norm": 13.647480010986328,
      "learning_rate": 1.978459722632045e-05,
      "loss": 0.3669,
      "step": 150
    },
    {
      "epoch": 0.05901445854234287,
      "grad_norm": 18.305370330810547,
      "learning_rate": 1.971082915314252e-05,
      "loss": 0.3361,
      "step": 200
    },
    {
      "epoch": 0.07376807317792859,
      "grad_norm": 8.100105285644531,
      "learning_rate": 1.963706107996459e-05,
      "loss": 0.3242,
      "step": 250
    },
    {
      "epoch": 0.08852168781351431,
      "grad_norm": 23.703289031982422,
      "learning_rate": 1.9563293006786662e-05,
      "loss": 0.3331,
      "step": 300
    },
    {
      "epoch": 0.10327530244910003,
      "grad_norm": 16.786855697631836,
      "learning_rate": 1.9489524933608736e-05,
      "loss": 0.3054,
      "step": 350
    },
    {
      "epoch": 0.11802891708468574,
      "grad_norm": 29.297719955444336,
      "learning_rate": 1.9415756860430807e-05,
      "loss": 0.3032,
      "step": 400
    },
    {
      "epoch": 0.13278253172027146,
      "grad_norm": 7.438453197479248,
      "learning_rate": 1.9341988787252878e-05,
      "loss": 0.2781,
      "step": 450
    },
    {
      "epoch": 0.14753614635585718,
      "grad_norm": 20.17772102355957,
      "learning_rate": 1.926822071407495e-05,
      "loss": 0.2886,
      "step": 500
    },
    {
      "epoch": 0.1622897609914429,
      "grad_norm": 28.54817771911621,
      "learning_rate": 1.919445264089702e-05,
      "loss": 0.297,
      "step": 550
    },
    {
      "epoch": 0.17704337562702863,
      "grad_norm": 18.9554443359375,
      "learning_rate": 1.9120684567719094e-05,
      "loss": 0.2682,
      "step": 600
    },
    {
      "epoch": 0.19179699026261435,
      "grad_norm": 23.837806701660156,
      "learning_rate": 1.9046916494541165e-05,
      "loss": 0.2616,
      "step": 650
    },
    {
      "epoch": 0.20655060489820007,
      "grad_norm": 14.594475746154785,
      "learning_rate": 1.8973148421363236e-05,
      "loss": 0.2973,
      "step": 700
    },
    {
      "epoch": 0.2213042195337858,
      "grad_norm": 10.83931827545166,
      "learning_rate": 1.8899380348185306e-05,
      "loss": 0.2688,
      "step": 750
    },
    {
      "epoch": 0.23605783416937148,
      "grad_norm": 20.457040786743164,
      "learning_rate": 1.8825612275007377e-05,
      "loss": 0.2784,
      "step": 800
    },
    {
      "epoch": 0.2508114488049572,
      "grad_norm": 21.230304718017578,
      "learning_rate": 1.875184420182945e-05,
      "loss": 0.2657,
      "step": 850
    },
    {
      "epoch": 0.2655650634405429,
      "grad_norm": 25.9968204498291,
      "learning_rate": 1.8678076128651522e-05,
      "loss": 0.2926,
      "step": 900
    },
    {
      "epoch": 0.28031867807612865,
      "grad_norm": 19.07137107849121,
      "learning_rate": 1.8604308055473593e-05,
      "loss": 0.2793,
      "step": 950
    },
    {
      "epoch": 0.29507229271171437,
      "grad_norm": 15.316678047180176,
      "learning_rate": 1.8530539982295664e-05,
      "loss": 0.2806,
      "step": 1000
    },
    {
      "epoch": 0.3098259073473001,
      "grad_norm": 15.96313190460205,
      "learning_rate": 1.8456771909117735e-05,
      "loss": 0.2518,
      "step": 1050
    },
    {
      "epoch": 0.3245795219828858,
      "grad_norm": 14.738668441772461,
      "learning_rate": 1.838300383593981e-05,
      "loss": 0.2685,
      "step": 1100
    },
    {
      "epoch": 0.33933313661847153,
      "grad_norm": 12.907753944396973,
      "learning_rate": 1.830923576276188e-05,
      "loss": 0.2655,
      "step": 1150
    },
    {
      "epoch": 0.35408675125405725,
      "grad_norm": 9.489592552185059,
      "learning_rate": 1.823546768958395e-05,
      "loss": 0.2771,
      "step": 1200
    },
    {
      "epoch": 0.368840365889643,
      "grad_norm": 7.896377086639404,
      "learning_rate": 1.816169961640602e-05,
      "loss": 0.295,
      "step": 1250
    },
    {
      "epoch": 0.3835939805252287,
      "grad_norm": 22.629671096801758,
      "learning_rate": 1.8087931543228092e-05,
      "loss": 0.2774,
      "step": 1300
    },
    {
      "epoch": 0.3983475951608144,
      "grad_norm": 12.766915321350098,
      "learning_rate": 1.8014163470050163e-05,
      "loss": 0.2587,
      "step": 1350
    },
    {
      "epoch": 0.41310120979640014,
      "grad_norm": 18.43453598022461,
      "learning_rate": 1.7940395396872234e-05,
      "loss": 0.2757,
      "step": 1400
    },
    {
      "epoch": 0.42785482443198586,
      "grad_norm": 5.63889741897583,
      "learning_rate": 1.7866627323694305e-05,
      "loss": 0.2521,
      "step": 1450
    },
    {
      "epoch": 0.4426084390675716,
      "grad_norm": 16.67283058166504,
      "learning_rate": 1.779285925051638e-05,
      "loss": 0.2782,
      "step": 1500
    },
    {
      "epoch": 0.4573620537031573,
      "grad_norm": 11.068676948547363,
      "learning_rate": 1.771909117733845e-05,
      "loss": 0.2575,
      "step": 1550
    },
    {
      "epoch": 0.47211566833874297,
      "grad_norm": 13.207789421081543,
      "learning_rate": 1.764532310416052e-05,
      "loss": 0.2662,
      "step": 1600
    },
    {
      "epoch": 0.4868692829743287,
      "grad_norm": 6.417616844177246,
      "learning_rate": 1.757155503098259e-05,
      "loss": 0.2672,
      "step": 1650
    },
    {
      "epoch": 0.5016228976099144,
      "grad_norm": 13.98190975189209,
      "learning_rate": 1.7497786957804662e-05,
      "loss": 0.2607,
      "step": 1700
    },
    {
      "epoch": 0.5163765122455002,
      "grad_norm": 56.860755920410156,
      "learning_rate": 1.7424018884626733e-05,
      "loss": 0.2528,
      "step": 1750
    },
    {
      "epoch": 0.5311301268810859,
      "grad_norm": 6.39507532119751,
      "learning_rate": 1.7350250811448804e-05,
      "loss": 0.2495,
      "step": 1800
    },
    {
      "epoch": 0.5458837415166716,
      "grad_norm": 7.952239036560059,
      "learning_rate": 1.7276482738270878e-05,
      "loss": 0.246,
      "step": 1850
    },
    {
      "epoch": 0.5606373561522573,
      "grad_norm": 8.95653247833252,
      "learning_rate": 1.720271466509295e-05,
      "loss": 0.2585,
      "step": 1900
    },
    {
      "epoch": 0.5753909707878431,
      "grad_norm": 14.418476104736328,
      "learning_rate": 1.712894659191502e-05,
      "loss": 0.2443,
      "step": 1950
    },
    {
      "epoch": 0.5901445854234287,
      "grad_norm": 20.09828758239746,
      "learning_rate": 1.705517851873709e-05,
      "loss": 0.246,
      "step": 2000
    },
    {
      "epoch": 0.6048982000590145,
      "grad_norm": 9.078170776367188,
      "learning_rate": 1.6981410445559165e-05,
      "loss": 0.2356,
      "step": 2050
    },
    {
      "epoch": 0.6196518146946002,
      "grad_norm": 26.492691040039062,
      "learning_rate": 1.6907642372381236e-05,
      "loss": 0.2284,
      "step": 2100
    },
    {
      "epoch": 0.6344054293301858,
      "grad_norm": 18.30030632019043,
      "learning_rate": 1.6833874299203306e-05,
      "loss": 0.2616,
      "step": 2150
    },
    {
      "epoch": 0.6491590439657716,
      "grad_norm": 19.44256019592285,
      "learning_rate": 1.6760106226025377e-05,
      "loss": 0.231,
      "step": 2200
    },
    {
      "epoch": 0.6639126586013573,
      "grad_norm": 11.152538299560547,
      "learning_rate": 1.668633815284745e-05,
      "loss": 0.232,
      "step": 2250
    },
    {
      "epoch": 0.6786662732369431,
      "grad_norm": 8.377274513244629,
      "learning_rate": 1.6612570079669522e-05,
      "loss": 0.2322,
      "step": 2300
    },
    {
      "epoch": 0.6934198878725287,
      "grad_norm": 17.92650032043457,
      "learning_rate": 1.6538802006491593e-05,
      "loss": 0.1981,
      "step": 2350
    },
    {
      "epoch": 0.7081735025081145,
      "grad_norm": 9.584328651428223,
      "learning_rate": 1.6465033933313664e-05,
      "loss": 0.2464,
      "step": 2400
    },
    {
      "epoch": 0.7229271171437002,
      "grad_norm": 16.703493118286133,
      "learning_rate": 1.6391265860135735e-05,
      "loss": 0.2267,
      "step": 2450
    },
    {
      "epoch": 0.737680731779286,
      "grad_norm": 19.0753116607666,
      "learning_rate": 1.6317497786957806e-05,
      "loss": 0.2214,
      "step": 2500
    },
    {
      "epoch": 0.7524343464148716,
      "grad_norm": 15.717314720153809,
      "learning_rate": 1.6243729713779876e-05,
      "loss": 0.2232,
      "step": 2550
    },
    {
      "epoch": 0.7671879610504574,
      "grad_norm": 11.410161018371582,
      "learning_rate": 1.6169961640601947e-05,
      "loss": 0.2258,
      "step": 2600
    },
    {
      "epoch": 0.7819415756860431,
      "grad_norm": 29.092914581298828,
      "learning_rate": 1.609619356742402e-05,
      "loss": 0.2356,
      "step": 2650
    },
    {
      "epoch": 0.7966951903216288,
      "grad_norm": 15.697946548461914,
      "learning_rate": 1.6022425494246092e-05,
      "loss": 0.2629,
      "step": 2700
    },
    {
      "epoch": 0.8114488049572145,
      "grad_norm": 10.823432922363281,
      "learning_rate": 1.5948657421068163e-05,
      "loss": 0.2097,
      "step": 2750
    },
    {
      "epoch": 0.8262024195928003,
      "grad_norm": 9.47752571105957,
      "learning_rate": 1.5874889347890234e-05,
      "loss": 0.2184,
      "step": 2800
    },
    {
      "epoch": 0.8409560342283859,
      "grad_norm": 7.9942946434021,
      "learning_rate": 1.5801121274712305e-05,
      "loss": 0.212,
      "step": 2850
    },
    {
      "epoch": 0.8557096488639717,
      "grad_norm": 15.737624168395996,
      "learning_rate": 1.5727353201534376e-05,
      "loss": 0.2134,
      "step": 2900
    },
    {
      "epoch": 0.8704632634995574,
      "grad_norm": 11.444342613220215,
      "learning_rate": 1.5653585128356446e-05,
      "loss": 0.2385,
      "step": 2950
    },
    {
      "epoch": 0.8852168781351432,
      "grad_norm": 13.559836387634277,
      "learning_rate": 1.557981705517852e-05,
      "loss": 0.2201,
      "step": 3000
    },
    {
      "epoch": 0.8999704927707288,
      "grad_norm": 13.680835723876953,
      "learning_rate": 1.550604898200059e-05,
      "loss": 0.2013,
      "step": 3050
    },
    {
      "epoch": 0.9147241074063146,
      "grad_norm": 10.851712226867676,
      "learning_rate": 1.5432280908822662e-05,
      "loss": 0.2242,
      "step": 3100
    },
    {
      "epoch": 0.9294777220419003,
      "grad_norm": 26.35713768005371,
      "learning_rate": 1.5358512835644733e-05,
      "loss": 0.2174,
      "step": 3150
    },
    {
      "epoch": 0.9442313366774859,
      "grad_norm": 17.868925094604492,
      "learning_rate": 1.5284744762466804e-05,
      "loss": 0.2028,
      "step": 3200
    },
    {
      "epoch": 0.9589849513130717,
      "grad_norm": 10.3679780960083,
      "learning_rate": 1.5210976689288877e-05,
      "loss": 0.1919,
      "step": 3250
    },
    {
      "epoch": 0.9737385659486574,
      "grad_norm": 10.55473804473877,
      "learning_rate": 1.5137208616110947e-05,
      "loss": 0.2068,
      "step": 3300
    },
    {
      "epoch": 0.9884921805842432,
      "grad_norm": 29.585487365722656,
      "learning_rate": 1.5063440542933018e-05,
      "loss": 0.2006,
      "step": 3350
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9025892593685453,
      "eval_f1": 0.8533999444907022,
      "eval_loss": 0.2210915982723236,
      "eval_precision": 0.9515969299331518,
      "eval_recall": 0.7735735131327363,
      "eval_runtime": 66.6251,
      "eval_samples_per_second": 406.934,
      "eval_steps_per_second": 12.728,
      "step": 3389
    },
    {
      "epoch": 1.0032457952198288,
      "grad_norm": 16.96598243713379,
      "learning_rate": 1.4989672469755092e-05,
      "loss": 0.2058,
      "step": 3400
    },
    {
      "epoch": 1.0179994098554146,
      "grad_norm": 7.5127410888671875,
      "learning_rate": 1.4915904396577163e-05,
      "loss": 0.1857,
      "step": 3450
    },
    {
      "epoch": 1.0327530244910004,
      "grad_norm": 49.05802917480469,
      "learning_rate": 1.4842136323399234e-05,
      "loss": 0.1697,
      "step": 3500
    },
    {
      "epoch": 1.047506639126586,
      "grad_norm": 2.7956058979034424,
      "learning_rate": 1.4768368250221305e-05,
      "loss": 0.1727,
      "step": 3550
    },
    {
      "epoch": 1.0622602537621717,
      "grad_norm": 18.061283111572266,
      "learning_rate": 1.4696075538506935e-05,
      "loss": 0.165,
      "step": 3600
    },
    {
      "epoch": 1.0770138683977575,
      "grad_norm": 20.004423141479492,
      "learning_rate": 1.4622307465329006e-05,
      "loss": 0.1585,
      "step": 3650
    },
    {
      "epoch": 1.0917674830333433,
      "grad_norm": 18.252967834472656,
      "learning_rate": 1.4548539392151077e-05,
      "loss": 0.1755,
      "step": 3700
    },
    {
      "epoch": 1.1065210976689288,
      "grad_norm": 21.52149200439453,
      "learning_rate": 1.4474771318973148e-05,
      "loss": 0.1666,
      "step": 3750
    },
    {
      "epoch": 1.1212747123045146,
      "grad_norm": 22.184127807617188,
      "learning_rate": 1.4401003245795222e-05,
      "loss": 0.1716,
      "step": 3800
    },
    {
      "epoch": 1.1360283269401004,
      "grad_norm": 24.110824584960938,
      "learning_rate": 1.4327235172617293e-05,
      "loss": 0.1546,
      "step": 3850
    },
    {
      "epoch": 1.1507819415756861,
      "grad_norm": 21.988866806030273,
      "learning_rate": 1.4253467099439364e-05,
      "loss": 0.181,
      "step": 3900
    },
    {
      "epoch": 1.1655355562112717,
      "grad_norm": 27.4445858001709,
      "learning_rate": 1.4179699026261435e-05,
      "loss": 0.1511,
      "step": 3950
    },
    {
      "epoch": 1.1802891708468575,
      "grad_norm": 16.927825927734375,
      "learning_rate": 1.4105930953083507e-05,
      "loss": 0.1784,
      "step": 4000
    },
    {
      "epoch": 1.1950427854824432,
      "grad_norm": 19.551342010498047,
      "learning_rate": 1.4032162879905578e-05,
      "loss": 0.1851,
      "step": 4050
    },
    {
      "epoch": 1.2097964001180288,
      "grad_norm": 34.52674102783203,
      "learning_rate": 1.3958394806727649e-05,
      "loss": 0.1622,
      "step": 4100
    },
    {
      "epoch": 1.2245500147536146,
      "grad_norm": 22.00955581665039,
      "learning_rate": 1.388462673354972e-05,
      "loss": 0.143,
      "step": 4150
    },
    {
      "epoch": 1.2393036293892004,
      "grad_norm": 33.73916244506836,
      "learning_rate": 1.3810858660371794e-05,
      "loss": 0.1656,
      "step": 4200
    },
    {
      "epoch": 1.2540572440247861,
      "grad_norm": 16.911300659179688,
      "learning_rate": 1.3737090587193865e-05,
      "loss": 0.1546,
      "step": 4250
    },
    {
      "epoch": 1.268810858660372,
      "grad_norm": 15.922121047973633,
      "learning_rate": 1.3663322514015935e-05,
      "loss": 0.1415,
      "step": 4300
    },
    {
      "epoch": 1.2835644732959575,
      "grad_norm": 23.80780792236328,
      "learning_rate": 1.3589554440838006e-05,
      "loss": 0.1706,
      "step": 4350
    },
    {
      "epoch": 1.2983180879315432,
      "grad_norm": 28.42357635498047,
      "learning_rate": 1.3515786367660077e-05,
      "loss": 0.1613,
      "step": 4400
    },
    {
      "epoch": 1.313071702567129,
      "grad_norm": 31.13276481628418,
      "learning_rate": 1.3442018294482148e-05,
      "loss": 0.1595,
      "step": 4450
    },
    {
      "epoch": 1.3278253172027146,
      "grad_norm": 15.990821838378906,
      "learning_rate": 1.336825022130422e-05,
      "loss": 0.1526,
      "step": 4500
    },
    {
      "epoch": 1.3425789318383003,
      "grad_norm": 15.602317810058594,
      "learning_rate": 1.3294482148126293e-05,
      "loss": 0.1515,
      "step": 4550
    },
    {
      "epoch": 1.3573325464738861,
      "grad_norm": 13.134761810302734,
      "learning_rate": 1.3220714074948364e-05,
      "loss": 0.1455,
      "step": 4600
    },
    {
      "epoch": 1.372086161109472,
      "grad_norm": 25.232847213745117,
      "learning_rate": 1.3146946001770435e-05,
      "loss": 0.1363,
      "step": 4650
    },
    {
      "epoch": 1.3868397757450575,
      "grad_norm": 12.808887481689453,
      "learning_rate": 1.3073177928592507e-05,
      "loss": 0.1382,
      "step": 4700
    },
    {
      "epoch": 1.4015933903806432,
      "grad_norm": 11.383330345153809,
      "learning_rate": 1.2999409855414578e-05,
      "loss": 0.1695,
      "step": 4750
    },
    {
      "epoch": 1.416347005016229,
      "grad_norm": 9.700582504272461,
      "learning_rate": 1.2925641782236649e-05,
      "loss": 0.1458,
      "step": 4800
    },
    {
      "epoch": 1.4311006196518146,
      "grad_norm": 8.072162628173828,
      "learning_rate": 1.285187370905872e-05,
      "loss": 0.1636,
      "step": 4850
    },
    {
      "epoch": 1.4458542342874003,
      "grad_norm": 12.137205123901367,
      "learning_rate": 1.277810563588079e-05,
      "loss": 0.1368,
      "step": 4900
    },
    {
      "epoch": 1.4606078489229861,
      "grad_norm": 35.34477615356445,
      "learning_rate": 1.2704337562702865e-05,
      "loss": 0.1306,
      "step": 4950
    },
    {
      "epoch": 1.475361463558572,
      "grad_norm": 31.35811996459961,
      "learning_rate": 1.2630569489524936e-05,
      "loss": 0.157,
      "step": 5000
    },
    {
      "epoch": 1.4901150781941577,
      "grad_norm": 21.140073776245117,
      "learning_rate": 1.2556801416347006e-05,
      "loss": 0.1458,
      "step": 5050
    },
    {
      "epoch": 1.5048686928297434,
      "grad_norm": 17.11158561706543,
      "learning_rate": 1.2483033343169077e-05,
      "loss": 0.1466,
      "step": 5100
    },
    {
      "epoch": 1.519622307465329,
      "grad_norm": 28.526233673095703,
      "learning_rate": 1.2409265269991148e-05,
      "loss": 0.1506,
      "step": 5150
    },
    {
      "epoch": 1.5343759221009146,
      "grad_norm": 13.471609115600586,
      "learning_rate": 1.233549719681322e-05,
      "loss": 0.1509,
      "step": 5200
    },
    {
      "epoch": 1.5491295367365003,
      "grad_norm": 20.89297866821289,
      "learning_rate": 1.2261729123635291e-05,
      "loss": 0.1299,
      "step": 5250
    },
    {
      "epoch": 1.5638831513720861,
      "grad_norm": 21.084692001342773,
      "learning_rate": 1.2187961050457362e-05,
      "loss": 0.1305,
      "step": 5300
    },
    {
      "epoch": 1.5786367660076719,
      "grad_norm": 32.804107666015625,
      "learning_rate": 1.2114192977279435e-05,
      "loss": 0.1551,
      "step": 5350
    },
    {
      "epoch": 1.5933903806432577,
      "grad_norm": 11.768656730651855,
      "learning_rate": 1.2040424904101507e-05,
      "loss": 0.153,
      "step": 5400
    },
    {
      "epoch": 1.6081439952788434,
      "grad_norm": 15.667191505432129,
      "learning_rate": 1.1966656830923578e-05,
      "loss": 0.1319,
      "step": 5450
    },
    {
      "epoch": 1.622897609914429,
      "grad_norm": 11.405047416687012,
      "learning_rate": 1.1892888757745649e-05,
      "loss": 0.149,
      "step": 5500
    },
    {
      "epoch": 1.6376512245500148,
      "grad_norm": 14.968426704406738,
      "learning_rate": 1.181912068456772e-05,
      "loss": 0.1573,
      "step": 5550
    },
    {
      "epoch": 1.6524048391856003,
      "grad_norm": 9.268739700317383,
      "learning_rate": 1.174535261138979e-05,
      "loss": 0.1123,
      "step": 5600
    },
    {
      "epoch": 1.667158453821186,
      "grad_norm": 0.7226022481918335,
      "learning_rate": 1.1671584538211861e-05,
      "loss": 0.1155,
      "step": 5650
    },
    {
      "epoch": 1.6819120684567719,
      "grad_norm": 25.936809539794922,
      "learning_rate": 1.1597816465033936e-05,
      "loss": 0.1514,
      "step": 5700
    },
    {
      "epoch": 1.6966656830923577,
      "grad_norm": 4.437021255493164,
      "learning_rate": 1.1525523753319564e-05,
      "loss": 0.1342,
      "step": 5750
    },
    {
      "epoch": 1.7114192977279434,
      "grad_norm": 7.340378761291504,
      "learning_rate": 1.1451755680141637e-05,
      "loss": 0.1281,
      "step": 5800
    },
    {
      "epoch": 1.7261729123635292,
      "grad_norm": 38.44197463989258,
      "learning_rate": 1.1377987606963708e-05,
      "loss": 0.1385,
      "step": 5850
    },
    {
      "epoch": 1.7409265269991148,
      "grad_norm": 19.646854400634766,
      "learning_rate": 1.1304219533785779e-05,
      "loss": 0.1441,
      "step": 5900
    },
    {
      "epoch": 1.7556801416347005,
      "grad_norm": 18.771682739257812,
      "learning_rate": 1.123045146060785e-05,
      "loss": 0.1074,
      "step": 5950
    },
    {
      "epoch": 1.770433756270286,
      "grad_norm": 68.22604370117188,
      "learning_rate": 1.115668338742992e-05,
      "loss": 0.1493,
      "step": 6000
    },
    {
      "epoch": 1.7851873709058719,
      "grad_norm": 18.19668197631836,
      "learning_rate": 1.1082915314251991e-05,
      "loss": 0.1472,
      "step": 6050
    },
    {
      "epoch": 1.7999409855414576,
      "grad_norm": 19.421070098876953,
      "learning_rate": 1.1009147241074064e-05,
      "loss": 0.1262,
      "step": 6100
    },
    {
      "epoch": 1.8146946001770434,
      "grad_norm": 14.443294525146484,
      "learning_rate": 1.0935379167896136e-05,
      "loss": 0.124,
      "step": 6150
    },
    {
      "epoch": 1.8294482148126292,
      "grad_norm": 23.4581356048584,
      "learning_rate": 1.0861611094718207e-05,
      "loss": 0.1235,
      "step": 6200
    },
    {
      "epoch": 1.8442018294482148,
      "grad_norm": 26.076244354248047,
      "learning_rate": 1.0787843021540278e-05,
      "loss": 0.1312,
      "step": 6250
    },
    {
      "epoch": 1.8589554440838005,
      "grad_norm": 24.008359909057617,
      "learning_rate": 1.071407494836235e-05,
      "loss": 0.1366,
      "step": 6300
    },
    {
      "epoch": 1.873709058719386,
      "grad_norm": 18.45757484436035,
      "learning_rate": 1.0640306875184421e-05,
      "loss": 0.1125,
      "step": 6350
    },
    {
      "epoch": 1.8884626733549719,
      "grad_norm": 15.518179893493652,
      "learning_rate": 1.0566538802006492e-05,
      "loss": 0.1521,
      "step": 6400
    },
    {
      "epoch": 1.9032162879905576,
      "grad_norm": 27.364089965820312,
      "learning_rate": 1.0492770728828563e-05,
      "loss": 0.1245,
      "step": 6450
    },
    {
      "epoch": 1.9179699026261434,
      "grad_norm": 8.647560119628906,
      "learning_rate": 1.0419002655650637e-05,
      "loss": 0.1092,
      "step": 6500
    },
    {
      "epoch": 1.9327235172617292,
      "grad_norm": 19.441158294677734,
      "learning_rate": 1.0345234582472708e-05,
      "loss": 0.1248,
      "step": 6550
    },
    {
      "epoch": 1.947477131897315,
      "grad_norm": 7.930138111114502,
      "learning_rate": 1.0271466509294779e-05,
      "loss": 0.1161,
      "step": 6600
    },
    {
      "epoch": 1.9622307465329005,
      "grad_norm": 27.12995719909668,
      "learning_rate": 1.019769843611685e-05,
      "loss": 0.1258,
      "step": 6650
    },
    {
      "epoch": 1.9769843611684863,
      "grad_norm": 36.4705696105957,
      "learning_rate": 1.012393036293892e-05,
      "loss": 0.1145,
      "step": 6700
    },
    {
      "epoch": 1.9917379758040719,
      "grad_norm": 59.33979034423828,
      "learning_rate": 1.0050162289760991e-05,
      "loss": 0.1151,
      "step": 6750
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9505385069341988,
      "eval_f1": 0.9309581424084847,
      "eval_loss": 0.14828503131866455,
      "eval_precision": 0.9530887623866751,
      "eval_recall": 0.9098319412297474,
      "eval_runtime": 66.6645,
      "eval_samples_per_second": 406.693,
      "eval_steps_per_second": 12.72,
      "step": 6778
    },
    {
      "epoch": 2.0064915904396576,
      "grad_norm": 24.441444396972656,
      "learning_rate": 9.976394216583064e-06,
      "loss": 0.0998,
      "step": 6800
    },
    {
      "epoch": 2.0212452050752434,
      "grad_norm": 5.410594940185547,
      "learning_rate": 9.902626143405135e-06,
      "loss": 0.0654,
      "step": 6850
    },
    {
      "epoch": 2.035998819710829,
      "grad_norm": 14.299525260925293,
      "learning_rate": 9.828858070227207e-06,
      "loss": 0.0786,
      "step": 6900
    },
    {
      "epoch": 2.050752434346415,
      "grad_norm": 0.9806305170059204,
      "learning_rate": 9.755089997049278e-06,
      "loss": 0.0805,
      "step": 6950
    },
    {
      "epoch": 2.0655060489820007,
      "grad_norm": 21.997282028198242,
      "learning_rate": 9.68132192387135e-06,
      "loss": 0.0685,
      "step": 7000
    },
    {
      "epoch": 2.0802596636175865,
      "grad_norm": 31.328271865844727,
      "learning_rate": 9.607553850693421e-06,
      "loss": 0.0633,
      "step": 7050
    },
    {
      "epoch": 2.095013278253172,
      "grad_norm": 41.789180755615234,
      "learning_rate": 9.533785777515492e-06,
      "loss": 0.0766,
      "step": 7100
    },
    {
      "epoch": 2.1097668928887576,
      "grad_norm": 55.92361831665039,
      "learning_rate": 9.460017704337563e-06,
      "loss": 0.0845,
      "step": 7150
    },
    {
      "epoch": 2.1245205075243434,
      "grad_norm": 50.288063049316406,
      "learning_rate": 9.386249631159635e-06,
      "loss": 0.0782,
      "step": 7200
    },
    {
      "epoch": 2.139274122159929,
      "grad_norm": 5.421708106994629,
      "learning_rate": 9.312481557981706e-06,
      "loss": 0.0428,
      "step": 7250
    },
    {
      "epoch": 2.154027736795515,
      "grad_norm": 50.6308708190918,
      "learning_rate": 9.238713484803777e-06,
      "loss": 0.0706,
      "step": 7300
    },
    {
      "epoch": 2.1687813514311007,
      "grad_norm": 3.587242603302002,
      "learning_rate": 9.16494541162585e-06,
      "loss": 0.072,
      "step": 7350
    },
    {
      "epoch": 2.1835349660666865,
      "grad_norm": 104.21903228759766,
      "learning_rate": 9.09117733844792e-06,
      "loss": 0.0835,
      "step": 7400
    },
    {
      "epoch": 2.198288580702272,
      "grad_norm": 13.240028381347656,
      "learning_rate": 9.017409265269991e-06,
      "loss": 0.0689,
      "step": 7450
    },
    {
      "epoch": 2.2130421953378576,
      "grad_norm": 55.0179557800293,
      "learning_rate": 8.943641192092064e-06,
      "loss": 0.0866,
      "step": 7500
    },
    {
      "epoch": 2.2277958099734434,
      "grad_norm": 61.17190933227539,
      "learning_rate": 8.869873118914135e-06,
      "loss": 0.0568,
      "step": 7550
    },
    {
      "epoch": 2.242549424609029,
      "grad_norm": 47.4355354309082,
      "learning_rate": 8.796105045736207e-06,
      "loss": 0.0818,
      "step": 7600
    },
    {
      "epoch": 2.257303039244615,
      "grad_norm": 44.75333786010742,
      "learning_rate": 8.722336972558278e-06,
      "loss": 0.0578,
      "step": 7650
    },
    {
      "epoch": 2.2720566538802007,
      "grad_norm": 55.52088165283203,
      "learning_rate": 8.650044260843907e-06,
      "loss": 0.0832,
      "step": 7700
    },
    {
      "epoch": 2.2868102685157865,
      "grad_norm": 2.063480854034424,
      "learning_rate": 8.576276187665978e-06,
      "loss": 0.072,
      "step": 7750
    },
    {
      "epoch": 2.3015638831513723,
      "grad_norm": 8.943115234375,
      "learning_rate": 8.50250811448805e-06,
      "loss": 0.0439,
      "step": 7800
    },
    {
      "epoch": 2.3163174977869576,
      "grad_norm": 1.0953876972198486,
      "learning_rate": 8.428740041310121e-06,
      "loss": 0.1022,
      "step": 7850
    },
    {
      "epoch": 2.3310711124225434,
      "grad_norm": 394.5274658203125,
      "learning_rate": 8.354971968132193e-06,
      "loss": 0.094,
      "step": 7900
    },
    {
      "epoch": 2.345824727058129,
      "grad_norm": 58.845298767089844,
      "learning_rate": 8.281203894954264e-06,
      "loss": 0.0781,
      "step": 7950
    },
    {
      "epoch": 2.360578341693715,
      "grad_norm": 1.8533793687820435,
      "learning_rate": 8.207435821776337e-06,
      "loss": 0.073,
      "step": 8000
    },
    {
      "epoch": 2.3753319563293007,
      "grad_norm": 29.39813995361328,
      "learning_rate": 8.133667748598408e-06,
      "loss": 0.0749,
      "step": 8050
    },
    {
      "epoch": 2.3900855709648865,
      "grad_norm": 97.28758239746094,
      "learning_rate": 8.059899675420478e-06,
      "loss": 0.0773,
      "step": 8100
    },
    {
      "epoch": 2.4048391856004723,
      "grad_norm": 124.62464141845703,
      "learning_rate": 7.986131602242551e-06,
      "loss": 0.1013,
      "step": 8150
    },
    {
      "epoch": 2.4195928002360576,
      "grad_norm": 2.3855981826782227,
      "learning_rate": 7.912363529064622e-06,
      "loss": 0.0778,
      "step": 8200
    },
    {
      "epoch": 2.4343464148716434,
      "grad_norm": 3.2467994689941406,
      "learning_rate": 7.838595455886693e-06,
      "loss": 0.0548,
      "step": 8250
    },
    {
      "epoch": 2.449100029507229,
      "grad_norm": 85.18807983398438,
      "learning_rate": 7.764827382708763e-06,
      "loss": 0.0784,
      "step": 8300
    },
    {
      "epoch": 2.463853644142815,
      "grad_norm": 7.071678161621094,
      "learning_rate": 7.691059309530836e-06,
      "loss": 0.0782,
      "step": 8350
    },
    {
      "epoch": 2.4786072587784007,
      "grad_norm": 2.2566847801208496,
      "learning_rate": 7.617291236352907e-06,
      "loss": 0.0932,
      "step": 8400
    },
    {
      "epoch": 2.4933608734139865,
      "grad_norm": 35.1834602355957,
      "learning_rate": 7.5435231631749785e-06,
      "loss": 0.0632,
      "step": 8450
    },
    {
      "epoch": 2.5081144880495723,
      "grad_norm": 61.96996307373047,
      "learning_rate": 7.469755089997049e-06,
      "loss": 0.0647,
      "step": 8500
    },
    {
      "epoch": 2.522868102685158,
      "grad_norm": 56.14004898071289,
      "learning_rate": 7.395987016819122e-06,
      "loss": 0.0675,
      "step": 8550
    },
    {
      "epoch": 2.537621717320744,
      "grad_norm": 3.6688506603240967,
      "learning_rate": 7.322218943641193e-06,
      "loss": 0.0535,
      "step": 8600
    },
    {
      "epoch": 2.552375331956329,
      "grad_norm": 17.77254295349121,
      "learning_rate": 7.2484508704632635e-06,
      "loss": 0.0621,
      "step": 8650
    },
    {
      "epoch": 2.567128946591915,
      "grad_norm": 0.4029625952243805,
      "learning_rate": 7.174682797285335e-06,
      "loss": 0.0606,
      "step": 8700
    },
    {
      "epoch": 2.5818825612275007,
      "grad_norm": 26.14571762084961,
      "learning_rate": 7.100914724107407e-06,
      "loss": 0.09,
      "step": 8750
    },
    {
      "epoch": 2.5966361758630865,
      "grad_norm": 1.4253064393997192,
      "learning_rate": 7.0271466509294785e-06,
      "loss": 0.0716,
      "step": 8800
    },
    {
      "epoch": 2.6113897904986723,
      "grad_norm": 45.931880950927734,
      "learning_rate": 6.953378577751549e-06,
      "loss": 0.0793,
      "step": 8850
    },
    {
      "epoch": 2.626143405134258,
      "grad_norm": 0.9852898120880127,
      "learning_rate": 6.87961050457362e-06,
      "loss": 0.096,
      "step": 8900
    },
    {
      "epoch": 2.6408970197698434,
      "grad_norm": 0.9947220087051392,
      "learning_rate": 6.805842431395693e-06,
      "loss": 0.079,
      "step": 8950
    },
    {
      "epoch": 2.655650634405429,
      "grad_norm": 46.45944595336914,
      "learning_rate": 6.7320743582177635e-06,
      "loss": 0.0791,
      "step": 9000
    },
    {
      "epoch": 2.670404249041015,
      "grad_norm": 4.517879009246826,
      "learning_rate": 6.658306285039835e-06,
      "loss": 0.0703,
      "step": 9050
    },
    {
      "epoch": 2.6851578636766007,
      "grad_norm": 105.1594467163086,
      "learning_rate": 6.584538211861907e-06,
      "loss": 0.0923,
      "step": 9100
    },
    {
      "epoch": 2.6999114783121865,
      "grad_norm": 0.0756247341632843,
      "learning_rate": 6.5107701386839786e-06,
      "loss": 0.0753,
      "step": 9150
    },
    {
      "epoch": 2.7146650929477723,
      "grad_norm": 6.5444560050964355,
      "learning_rate": 6.437002065506049e-06,
      "loss": 0.095,
      "step": 9200
    },
    {
      "epoch": 2.729418707583358,
      "grad_norm": 1.3361481428146362,
      "learning_rate": 6.36323399232812e-06,
      "loss": 0.0409,
      "step": 9250
    },
    {
      "epoch": 2.744172322218944,
      "grad_norm": 40.35375213623047,
      "learning_rate": 6.289465919150193e-06,
      "loss": 0.0738,
      "step": 9300
    },
    {
      "epoch": 2.7589259368545296,
      "grad_norm": 4.825938701629639,
      "learning_rate": 6.2156978459722636e-06,
      "loss": 0.056,
      "step": 9350
    },
    {
      "epoch": 2.773679551490115,
      "grad_norm": 61.6106071472168,
      "learning_rate": 6.141929772794335e-06,
      "loss": 0.0782,
      "step": 9400
    },
    {
      "epoch": 2.7884331661257007,
      "grad_norm": 96.90959167480469,
      "learning_rate": 6.068161699616406e-06,
      "loss": 0.0815,
      "step": 9450
    },
    {
      "epoch": 2.8031867807612865,
      "grad_norm": 0.2948722243309021,
      "learning_rate": 5.994393626438479e-06,
      "loss": 0.0666,
      "step": 9500
    },
    {
      "epoch": 2.8179403953968722,
      "grad_norm": 87.23224639892578,
      "learning_rate": 5.920625553260549e-06,
      "loss": 0.078,
      "step": 9550
    },
    {
      "epoch": 2.832694010032458,
      "grad_norm": 7.426484107971191,
      "learning_rate": 5.84685748008262e-06,
      "loss": 0.0637,
      "step": 9600
    },
    {
      "epoch": 2.847447624668044,
      "grad_norm": 0.4949687123298645,
      "learning_rate": 5.773089406904692e-06,
      "loss": 0.0674,
      "step": 9650
    },
    {
      "epoch": 2.862201239303629,
      "grad_norm": 8.341346740722656,
      "learning_rate": 5.699321333726764e-06,
      "loss": 0.0585,
      "step": 9700
    },
    {
      "epoch": 2.876954853939215,
      "grad_norm": 0.19785048067569733,
      "learning_rate": 5.625553260548835e-06,
      "loss": 0.0696,
      "step": 9750
    },
    {
      "epoch": 2.8917084685748007,
      "grad_norm": 0.27886396646499634,
      "learning_rate": 5.553260548834465e-06,
      "loss": 0.0657,
      "step": 9800
    },
    {
      "epoch": 2.9064620832103865,
      "grad_norm": 2.7574069499969482,
      "learning_rate": 5.479492475656536e-06,
      "loss": 0.0667,
      "step": 9850
    },
    {
      "epoch": 2.9212156978459722,
      "grad_norm": 0.46065589785575867,
      "learning_rate": 5.405724402478608e-06,
      "loss": 0.0795,
      "step": 9900
    },
    {
      "epoch": 2.935969312481558,
      "grad_norm": 0.24229678511619568,
      "learning_rate": 5.331956329300679e-06,
      "loss": 0.0736,
      "step": 9950
    },
    {
      "epoch": 2.950722927117144,
      "grad_norm": 0.7634821534156799,
      "learning_rate": 5.258188256122751e-06,
      "loss": 0.0888,
      "step": 10000
    },
    {
      "epoch": 2.9654765417527296,
      "grad_norm": 0.8990203738212585,
      "learning_rate": 5.184420182944822e-06,
      "loss": 0.0686,
      "step": 10050
    },
    {
      "epoch": 2.9802301563883153,
      "grad_norm": 2.5161352157592773,
      "learning_rate": 5.110652109766893e-06,
      "loss": 0.0589,
      "step": 10100
    },
    {
      "epoch": 2.994983771023901,
      "grad_norm": 0.07354554533958435,
      "learning_rate": 5.036884036588965e-06,
      "loss": 0.0397,
      "step": 10150
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9699763942165831,
      "eval_f1": 0.9585666293393057,
      "eval_loss": 0.15928304195404053,
      "eval_precision": 0.969821814811,
      "eval_recall": 0.9475696890409581,
      "eval_runtime": 68.2921,
      "eval_samples_per_second": 397.0,
      "eval_steps_per_second": 12.417,
      "step": 10167
    }
  ],
  "logging_steps": 50,
  "max_steps": 13556,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1943704310446080.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
