{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 6778,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014753614635585718,
      "grad_norm": 23.847089767456055,
      "learning_rate": 1.9861316022425495e-05,
      "loss": 0.5318,
      "step": 50
    },
    {
      "epoch": 0.029507229271171435,
      "grad_norm": 26.378890991210938,
      "learning_rate": 1.971377987606964e-05,
      "loss": 0.4029,
      "step": 100
    },
    {
      "epoch": 0.04426084390675716,
      "grad_norm": 40.67231369018555,
      "learning_rate": 1.956624372971378e-05,
      "loss": 0.3574,
      "step": 150
    },
    {
      "epoch": 0.05901445854234287,
      "grad_norm": 14.73836898803711,
      "learning_rate": 1.9418707583357927e-05,
      "loss": 0.3345,
      "step": 200
    },
    {
      "epoch": 0.07376807317792859,
      "grad_norm": 12.398255348205566,
      "learning_rate": 1.927117143700207e-05,
      "loss": 0.3347,
      "step": 250
    },
    {
      "epoch": 0.08852168781351431,
      "grad_norm": 12.978330612182617,
      "learning_rate": 1.912363529064621e-05,
      "loss": 0.3216,
      "step": 300
    },
    {
      "epoch": 0.10327530244910003,
      "grad_norm": 59.53179168701172,
      "learning_rate": 1.897904986721747e-05,
      "loss": 0.3063,
      "step": 350
    },
    {
      "epoch": 0.11802891708468574,
      "grad_norm": 30.771419525146484,
      "learning_rate": 1.883446444378873e-05,
      "loss": 0.3029,
      "step": 400
    },
    {
      "epoch": 0.13278253172027146,
      "grad_norm": 11.63904094696045,
      "learning_rate": 1.8686928297432874e-05,
      "loss": 0.3001,
      "step": 450
    },
    {
      "epoch": 0.14753614635585718,
      "grad_norm": 21.82642364501953,
      "learning_rate": 1.8539392151077016e-05,
      "loss": 0.2694,
      "step": 500
    },
    {
      "epoch": 0.1622897609914429,
      "grad_norm": 15.971054077148438,
      "learning_rate": 1.8391856004721157e-05,
      "loss": 0.2887,
      "step": 550
    },
    {
      "epoch": 0.17704337562702863,
      "grad_norm": 11.661199569702148,
      "learning_rate": 1.82443198583653e-05,
      "loss": 0.2692,
      "step": 600
    },
    {
      "epoch": 0.19179699026261435,
      "grad_norm": 21.022140502929688,
      "learning_rate": 1.8096783712009444e-05,
      "loss": 0.2804,
      "step": 650
    },
    {
      "epoch": 0.20655060489820007,
      "grad_norm": 11.852729797363281,
      "learning_rate": 1.7952198288580705e-05,
      "loss": 0.293,
      "step": 700
    },
    {
      "epoch": 0.2213042195337858,
      "grad_norm": 9.042975425720215,
      "learning_rate": 1.7804662142224847e-05,
      "loss": 0.2743,
      "step": 750
    },
    {
      "epoch": 0.23605783416937148,
      "grad_norm": 20.081932067871094,
      "learning_rate": 1.765712599586899e-05,
      "loss": 0.2829,
      "step": 800
    },
    {
      "epoch": 0.2508114488049572,
      "grad_norm": 15.7952241897583,
      "learning_rate": 1.750958984951313e-05,
      "loss": 0.2809,
      "step": 850
    },
    {
      "epoch": 0.2655650634405429,
      "grad_norm": 21.543550491333008,
      "learning_rate": 1.7362053703157275e-05,
      "loss": 0.304,
      "step": 900
    },
    {
      "epoch": 0.28031867807612865,
      "grad_norm": 32.04381561279297,
      "learning_rate": 1.7214517556801417e-05,
      "loss": 0.2811,
      "step": 950
    },
    {
      "epoch": 0.29507229271171437,
      "grad_norm": 14.85956859588623,
      "learning_rate": 1.706698141044556e-05,
      "loss": 0.2879,
      "step": 1000
    },
    {
      "epoch": 0.3098259073473001,
      "grad_norm": 19.77912712097168,
      "learning_rate": 1.6919445264089703e-05,
      "loss": 0.2432,
      "step": 1050
    },
    {
      "epoch": 0.3245795219828858,
      "grad_norm": 36.701576232910156,
      "learning_rate": 1.6771909117733845e-05,
      "loss": 0.2723,
      "step": 1100
    },
    {
      "epoch": 0.33933313661847153,
      "grad_norm": 14.142216682434082,
      "learning_rate": 1.662437297137799e-05,
      "loss": 0.2824,
      "step": 1150
    },
    {
      "epoch": 0.35408675125405725,
      "grad_norm": 19.05000114440918,
      "learning_rate": 1.6476836825022132e-05,
      "loss": 0.2777,
      "step": 1200
    },
    {
      "epoch": 0.368840365889643,
      "grad_norm": 11.194072723388672,
      "learning_rate": 1.6329300678666277e-05,
      "loss": 0.3015,
      "step": 1250
    },
    {
      "epoch": 0.3835939805252287,
      "grad_norm": 18.244022369384766,
      "learning_rate": 1.618176453231042e-05,
      "loss": 0.2822,
      "step": 1300
    },
    {
      "epoch": 0.3983475951608144,
      "grad_norm": 37.646297454833984,
      "learning_rate": 1.603422838595456e-05,
      "loss": 0.2742,
      "step": 1350
    },
    {
      "epoch": 0.41310120979640014,
      "grad_norm": 13.621655464172363,
      "learning_rate": 1.5886692239598702e-05,
      "loss": 0.273,
      "step": 1400
    },
    {
      "epoch": 0.42785482443198586,
      "grad_norm": 8.834137916564941,
      "learning_rate": 1.5739156093242847e-05,
      "loss": 0.2705,
      "step": 1450
    },
    {
      "epoch": 0.4426084390675716,
      "grad_norm": 19.128536224365234,
      "learning_rate": 1.559161994688699e-05,
      "loss": 0.2717,
      "step": 1500
    },
    {
      "epoch": 0.4573620537031573,
      "grad_norm": 21.617244720458984,
      "learning_rate": 1.544408380053113e-05,
      "loss": 0.2544,
      "step": 1550
    },
    {
      "epoch": 0.47211566833874297,
      "grad_norm": 11.765403747558594,
      "learning_rate": 1.5296547654175272e-05,
      "loss": 0.2593,
      "step": 1600
    },
    {
      "epoch": 0.4868692829743287,
      "grad_norm": 6.82732629776001,
      "learning_rate": 1.5149011507819418e-05,
      "loss": 0.2661,
      "step": 1650
    },
    {
      "epoch": 0.5016228976099144,
      "grad_norm": 12.997520446777344,
      "learning_rate": 1.500147536146356e-05,
      "loss": 0.2444,
      "step": 1700
    },
    {
      "epoch": 0.5163765122455002,
      "grad_norm": 19.3341007232666,
      "learning_rate": 1.4853939215107702e-05,
      "loss": 0.2608,
      "step": 1750
    },
    {
      "epoch": 0.5311301268810859,
      "grad_norm": 8.841188430786133,
      "learning_rate": 1.4706403068751845e-05,
      "loss": 0.2401,
      "step": 1800
    },
    {
      "epoch": 0.5458837415166716,
      "grad_norm": 15.83041000366211,
      "learning_rate": 1.4558866922395988e-05,
      "loss": 0.2501,
      "step": 1850
    },
    {
      "epoch": 0.5606373561522573,
      "grad_norm": 7.780704021453857,
      "learning_rate": 1.4411330776040132e-05,
      "loss": 0.2652,
      "step": 1900
    },
    {
      "epoch": 0.5753909707878431,
      "grad_norm": 38.97016143798828,
      "learning_rate": 1.4263794629684273e-05,
      "loss": 0.2685,
      "step": 1950
    },
    {
      "epoch": 0.5901445854234287,
      "grad_norm": 18.452743530273438,
      "learning_rate": 1.4119209206255533e-05,
      "loss": 0.2536,
      "step": 2000
    },
    {
      "epoch": 0.6048982000590145,
      "grad_norm": 12.708842277526855,
      "learning_rate": 1.3971673059899678e-05,
      "loss": 0.2326,
      "step": 2050
    },
    {
      "epoch": 0.6196518146946002,
      "grad_norm": 11.039215087890625,
      "learning_rate": 1.382413691354382e-05,
      "loss": 0.2267,
      "step": 2100
    },
    {
      "epoch": 0.6344054293301858,
      "grad_norm": 18.69455337524414,
      "learning_rate": 1.3676600767187961e-05,
      "loss": 0.2565,
      "step": 2150
    },
    {
      "epoch": 0.6491590439657716,
      "grad_norm": 9.265626907348633,
      "learning_rate": 1.3529064620832105e-05,
      "loss": 0.2339,
      "step": 2200
    },
    {
      "epoch": 0.6639126586013573,
      "grad_norm": 12.750293731689453,
      "learning_rate": 1.3381528474476248e-05,
      "loss": 0.2378,
      "step": 2250
    },
    {
      "epoch": 0.6786662732369431,
      "grad_norm": 8.139863014221191,
      "learning_rate": 1.3233992328120391e-05,
      "loss": 0.2208,
      "step": 2300
    },
    {
      "epoch": 0.6934198878725287,
      "grad_norm": 18.951311111450195,
      "learning_rate": 1.3086456181764533e-05,
      "loss": 0.2025,
      "step": 2350
    },
    {
      "epoch": 0.7081735025081145,
      "grad_norm": 8.20529842376709,
      "learning_rate": 1.2938920035408675e-05,
      "loss": 0.2367,
      "step": 2400
    },
    {
      "epoch": 0.7229271171437002,
      "grad_norm": 11.86007022857666,
      "learning_rate": 1.279138388905282e-05,
      "loss": 0.2345,
      "step": 2450
    },
    {
      "epoch": 0.737680731779286,
      "grad_norm": 8.465018272399902,
      "learning_rate": 1.2643847742696961e-05,
      "loss": 0.2111,
      "step": 2500
    },
    {
      "epoch": 0.7524343464148716,
      "grad_norm": 20.673715591430664,
      "learning_rate": 1.2496311596341105e-05,
      "loss": 0.2205,
      "step": 2550
    },
    {
      "epoch": 0.7671879610504574,
      "grad_norm": 10.271485328674316,
      "learning_rate": 1.2348775449985246e-05,
      "loss": 0.2152,
      "step": 2600
    },
    {
      "epoch": 0.7819415756860431,
      "grad_norm": 10.810853958129883,
      "learning_rate": 1.2201239303629391e-05,
      "loss": 0.2294,
      "step": 2650
    },
    {
      "epoch": 0.7966951903216288,
      "grad_norm": 16.553739547729492,
      "learning_rate": 1.2053703157273533e-05,
      "loss": 0.2553,
      "step": 2700
    },
    {
      "epoch": 0.8114488049572145,
      "grad_norm": 6.733879089355469,
      "learning_rate": 1.1906167010917675e-05,
      "loss": 0.2112,
      "step": 2750
    },
    {
      "epoch": 0.8262024195928003,
      "grad_norm": 16.00786018371582,
      "learning_rate": 1.175863086456182e-05,
      "loss": 0.2175,
      "step": 2800
    },
    {
      "epoch": 0.8409560342283859,
      "grad_norm": 10.475824356079102,
      "learning_rate": 1.1611094718205961e-05,
      "loss": 0.2146,
      "step": 2850
    },
    {
      "epoch": 0.8557096488639717,
      "grad_norm": 22.089696884155273,
      "learning_rate": 1.1463558571850105e-05,
      "loss": 0.2119,
      "step": 2900
    },
    {
      "epoch": 0.8704632634995574,
      "grad_norm": 15.649863243103027,
      "learning_rate": 1.1316022425494246e-05,
      "loss": 0.2234,
      "step": 2950
    },
    {
      "epoch": 0.8852168781351432,
      "grad_norm": 18.604509353637695,
      "learning_rate": 1.1168486279138391e-05,
      "loss": 0.224,
      "step": 3000
    },
    {
      "epoch": 0.8999704927707288,
      "grad_norm": 12.458653450012207,
      "learning_rate": 1.1020950132782533e-05,
      "loss": 0.2113,
      "step": 3050
    },
    {
      "epoch": 0.9147241074063146,
      "grad_norm": 17.02798080444336,
      "learning_rate": 1.0873413986426675e-05,
      "loss": 0.2363,
      "step": 3100
    },
    {
      "epoch": 0.9294777220419003,
      "grad_norm": 20.60870933532715,
      "learning_rate": 1.0725877840070818e-05,
      "loss": 0.2055,
      "step": 3150
    },
    {
      "epoch": 0.9442313366774859,
      "grad_norm": 19.62511444091797,
      "learning_rate": 1.0578341693714961e-05,
      "loss": 0.2036,
      "step": 3200
    },
    {
      "epoch": 0.9589849513130717,
      "grad_norm": 6.520667552947998,
      "learning_rate": 1.0430805547359105e-05,
      "loss": 0.1995,
      "step": 3250
    },
    {
      "epoch": 0.9737385659486574,
      "grad_norm": 17.304393768310547,
      "learning_rate": 1.0283269401003246e-05,
      "loss": 0.2087,
      "step": 3300
    },
    {
      "epoch": 0.9884921805842432,
      "grad_norm": 28.82863998413086,
      "learning_rate": 1.0135733254647388e-05,
      "loss": 0.179,
      "step": 3350
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9074948362348776,
      "eval_f1": 0.863843648208469,
      "eval_loss": 0.2079961746931076,
      "eval_precision": 0.9378757515030061,
      "eval_recall": 0.8006440575626447,
      "eval_runtime": 67.1928,
      "eval_samples_per_second": 403.495,
      "eval_steps_per_second": 12.62,
      "step": 3389
    },
    {
      "epoch": 1.0032457952198288,
      "grad_norm": 15.938426971435547,
      "learning_rate": 9.988197108291531e-06,
      "loss": 0.2217,
      "step": 3400
    },
    {
      "epoch": 1.0179994098554146,
      "grad_norm": 13.413724899291992,
      "learning_rate": 9.840660961935675e-06,
      "loss": 0.1855,
      "step": 3450
    },
    {
      "epoch": 1.0327530244910004,
      "grad_norm": 18.318944931030273,
      "learning_rate": 9.693124815579818e-06,
      "loss": 0.1527,
      "step": 3500
    },
    {
      "epoch": 1.047506639126586,
      "grad_norm": 12.234030723571777,
      "learning_rate": 9.545588669223961e-06,
      "loss": 0.1803,
      "step": 3550
    },
    {
      "epoch": 1.0622602537621717,
      "grad_norm": 22.35915184020996,
      "learning_rate": 9.398052522868103e-06,
      "loss": 0.1411,
      "step": 3600
    },
    {
      "epoch": 1.0770138683977575,
      "grad_norm": 11.222188949584961,
      "learning_rate": 9.250516376512246e-06,
      "loss": 0.1559,
      "step": 3650
    },
    {
      "epoch": 1.0917674830333433,
      "grad_norm": 17.503284454345703,
      "learning_rate": 9.102980230156388e-06,
      "loss": 0.1559,
      "step": 3700
    },
    {
      "epoch": 1.1065210976689288,
      "grad_norm": 27.429630279541016,
      "learning_rate": 8.955444083800531e-06,
      "loss": 0.1541,
      "step": 3750
    },
    {
      "epoch": 1.1212747123045146,
      "grad_norm": 9.96324634552002,
      "learning_rate": 8.807907937444675e-06,
      "loss": 0.1511,
      "step": 3800
    },
    {
      "epoch": 1.1360283269401004,
      "grad_norm": 6.985859394073486,
      "learning_rate": 8.660371791088818e-06,
      "loss": 0.1495,
      "step": 3850
    },
    {
      "epoch": 1.1507819415756861,
      "grad_norm": 21.684860229492188,
      "learning_rate": 8.512835644732961e-06,
      "loss": 0.1856,
      "step": 3900
    },
    {
      "epoch": 1.1655355562112717,
      "grad_norm": 16.529266357421875,
      "learning_rate": 8.365299498377103e-06,
      "loss": 0.1464,
      "step": 3950
    },
    {
      "epoch": 1.1802891708468575,
      "grad_norm": 25.362014770507812,
      "learning_rate": 8.217763352021247e-06,
      "loss": 0.1821,
      "step": 4000
    },
    {
      "epoch": 1.1950427854824432,
      "grad_norm": 33.01773452758789,
      "learning_rate": 8.070227205665388e-06,
      "loss": 0.1483,
      "step": 4050
    },
    {
      "epoch": 1.2097964001180288,
      "grad_norm": 31.709396362304688,
      "learning_rate": 7.922691059309532e-06,
      "loss": 0.1451,
      "step": 4100
    },
    {
      "epoch": 1.2245500147536146,
      "grad_norm": 39.67638397216797,
      "learning_rate": 7.775154912953675e-06,
      "loss": 0.1451,
      "step": 4150
    },
    {
      "epoch": 1.2393036293892004,
      "grad_norm": 35.2422981262207,
      "learning_rate": 7.627618766597817e-06,
      "loss": 0.1439,
      "step": 4200
    },
    {
      "epoch": 1.2540572440247861,
      "grad_norm": 18.612661361694336,
      "learning_rate": 7.48008262024196e-06,
      "loss": 0.1367,
      "step": 4250
    },
    {
      "epoch": 1.268810858660372,
      "grad_norm": 34.212425231933594,
      "learning_rate": 7.332546473886103e-06,
      "loss": 0.1445,
      "step": 4300
    },
    {
      "epoch": 1.2835644732959575,
      "grad_norm": 36.71806335449219,
      "learning_rate": 7.185010327530245e-06,
      "loss": 0.1521,
      "step": 4350
    },
    {
      "epoch": 1.2983180879315432,
      "grad_norm": 44.55110168457031,
      "learning_rate": 7.037474181174388e-06,
      "loss": 0.136,
      "step": 4400
    },
    {
      "epoch": 1.313071702567129,
      "grad_norm": 35.710811614990234,
      "learning_rate": 6.889938034818531e-06,
      "loss": 0.1579,
      "step": 4450
    },
    {
      "epoch": 1.3278253172027146,
      "grad_norm": 20.99329376220703,
      "learning_rate": 6.742401888462674e-06,
      "loss": 0.1292,
      "step": 4500
    },
    {
      "epoch": 1.3425789318383003,
      "grad_norm": 17.043399810791016,
      "learning_rate": 6.5948657421068166e-06,
      "loss": 0.1298,
      "step": 4550
    },
    {
      "epoch": 1.3573325464738861,
      "grad_norm": 25.98802947998047,
      "learning_rate": 6.44732959575096e-06,
      "loss": 0.1244,
      "step": 4600
    },
    {
      "epoch": 1.372086161109472,
      "grad_norm": 16.0659236907959,
      "learning_rate": 6.2997934493951016e-06,
      "loss": 0.1219,
      "step": 4650
    },
    {
      "epoch": 1.3868397757450575,
      "grad_norm": 19.049922943115234,
      "learning_rate": 6.152257303039245e-06,
      "loss": 0.1199,
      "step": 4700
    },
    {
      "epoch": 1.4015933903806432,
      "grad_norm": 12.779786109924316,
      "learning_rate": 6.004721156683387e-06,
      "loss": 0.15,
      "step": 4750
    },
    {
      "epoch": 1.416347005016229,
      "grad_norm": 7.906422138214111,
      "learning_rate": 5.857185010327531e-06,
      "loss": 0.1279,
      "step": 4800
    },
    {
      "epoch": 1.4311006196518146,
      "grad_norm": 14.421358108520508,
      "learning_rate": 5.709648863971674e-06,
      "loss": 0.1474,
      "step": 4850
    },
    {
      "epoch": 1.4458542342874003,
      "grad_norm": 6.933222770690918,
      "learning_rate": 5.562112717615817e-06,
      "loss": 0.1426,
      "step": 4900
    },
    {
      "epoch": 1.4606078489229861,
      "grad_norm": 26.741622924804688,
      "learning_rate": 5.41457657125996e-06,
      "loss": 0.1089,
      "step": 4950
    },
    {
      "epoch": 1.475361463558572,
      "grad_norm": 45.1923713684082,
      "learning_rate": 5.267040424904102e-06,
      "loss": 0.1344,
      "step": 5000
    },
    {
      "epoch": 1.4901150781941577,
      "grad_norm": 21.89215660095215,
      "learning_rate": 5.119504278548245e-06,
      "loss": 0.1345,
      "step": 5050
    },
    {
      "epoch": 1.5048686928297434,
      "grad_norm": 6.833537578582764,
      "learning_rate": 4.9719681321923875e-06,
      "loss": 0.1325,
      "step": 5100
    },
    {
      "epoch": 1.519622307465329,
      "grad_norm": 34.8340950012207,
      "learning_rate": 4.82443198583653e-06,
      "loss": 0.1351,
      "step": 5150
    },
    {
      "epoch": 1.5343759221009146,
      "grad_norm": 16.094158172607422,
      "learning_rate": 4.676895839480673e-06,
      "loss": 0.133,
      "step": 5200
    },
    {
      "epoch": 1.5491295367365003,
      "grad_norm": 23.62405014038086,
      "learning_rate": 4.529359693124816e-06,
      "loss": 0.1198,
      "step": 5250
    },
    {
      "epoch": 1.5638831513720861,
      "grad_norm": 27.193920135498047,
      "learning_rate": 4.381823546768958e-06,
      "loss": 0.1206,
      "step": 5300
    },
    {
      "epoch": 1.5786367660076719,
      "grad_norm": 28.243824005126953,
      "learning_rate": 4.234287400413102e-06,
      "loss": 0.1236,
      "step": 5350
    },
    {
      "epoch": 1.5933903806432577,
      "grad_norm": 32.56437683105469,
      "learning_rate": 4.086751254057245e-06,
      "loss": 0.1156,
      "step": 5400
    },
    {
      "epoch": 1.6081439952788434,
      "grad_norm": 12.338047981262207,
      "learning_rate": 3.9392151077013875e-06,
      "loss": 0.102,
      "step": 5450
    },
    {
      "epoch": 1.622897609914429,
      "grad_norm": 27.204736709594727,
      "learning_rate": 3.79167896134553e-06,
      "loss": 0.1436,
      "step": 5500
    },
    {
      "epoch": 1.6376512245500148,
      "grad_norm": 50.25445556640625,
      "learning_rate": 3.644142814989673e-06,
      "loss": 0.1281,
      "step": 5550
    },
    {
      "epoch": 1.6524048391856003,
      "grad_norm": 11.315268516540527,
      "learning_rate": 3.496606668633816e-06,
      "loss": 0.0966,
      "step": 5600
    },
    {
      "epoch": 1.667158453821186,
      "grad_norm": 2.6720945835113525,
      "learning_rate": 3.3490705222779584e-06,
      "loss": 0.097,
      "step": 5650
    },
    {
      "epoch": 1.6819120684567719,
      "grad_norm": 30.41221046447754,
      "learning_rate": 3.2015343759221013e-06,
      "loss": 0.1152,
      "step": 5700
    },
    {
      "epoch": 1.6966656830923577,
      "grad_norm": 15.644516944885254,
      "learning_rate": 3.053998229566244e-06,
      "loss": 0.1261,
      "step": 5750
    },
    {
      "epoch": 1.7114192977279434,
      "grad_norm": 3.649336814880371,
      "learning_rate": 2.9064620832103867e-06,
      "loss": 0.0996,
      "step": 5800
    },
    {
      "epoch": 1.7261729123635292,
      "grad_norm": 17.83443260192871,
      "learning_rate": 2.7589259368545296e-06,
      "loss": 0.1282,
      "step": 5850
    },
    {
      "epoch": 1.7409265269991148,
      "grad_norm": 11.829421043395996,
      "learning_rate": 2.6113897904986726e-06,
      "loss": 0.1214,
      "step": 5900
    },
    {
      "epoch": 1.7556801416347005,
      "grad_norm": 9.71034049987793,
      "learning_rate": 2.463853644142815e-06,
      "loss": 0.0947,
      "step": 5950
    },
    {
      "epoch": 1.770433756270286,
      "grad_norm": 33.697593688964844,
      "learning_rate": 2.316317497786958e-06,
      "loss": 0.1261,
      "step": 6000
    },
    {
      "epoch": 1.7851873709058719,
      "grad_norm": 4.599642753601074,
      "learning_rate": 2.1687813514311005e-06,
      "loss": 0.1291,
      "step": 6050
    },
    {
      "epoch": 1.7999409855414576,
      "grad_norm": 14.56802749633789,
      "learning_rate": 2.0212452050752434e-06,
      "loss": 0.1023,
      "step": 6100
    },
    {
      "epoch": 1.8146946001770434,
      "grad_norm": 18.10674476623535,
      "learning_rate": 1.8737090587193865e-06,
      "loss": 0.0978,
      "step": 6150
    },
    {
      "epoch": 1.8294482148126292,
      "grad_norm": 5.222599983215332,
      "learning_rate": 1.7261729123635293e-06,
      "loss": 0.0981,
      "step": 6200
    },
    {
      "epoch": 1.8442018294482148,
      "grad_norm": 28.81907081604004,
      "learning_rate": 1.578636766007672e-06,
      "loss": 0.1249,
      "step": 6250
    },
    {
      "epoch": 1.8589554440838005,
      "grad_norm": 20.269874572753906,
      "learning_rate": 1.431100619651815e-06,
      "loss": 0.1081,
      "step": 6300
    },
    {
      "epoch": 1.873709058719386,
      "grad_norm": 16.562376022338867,
      "learning_rate": 1.2835644732959576e-06,
      "loss": 0.1022,
      "step": 6350
    },
    {
      "epoch": 1.8884626733549719,
      "grad_norm": 31.73488426208496,
      "learning_rate": 1.1389790498672175e-06,
      "loss": 0.1178,
      "step": 6400
    },
    {
      "epoch": 1.9032162879905576,
      "grad_norm": 10.927957534790039,
      "learning_rate": 9.914429035113604e-07,
      "loss": 0.1016,
      "step": 6450
    },
    {
      "epoch": 1.9179699026261434,
      "grad_norm": 13.283292770385742,
      "learning_rate": 8.439067571555032e-07,
      "loss": 0.0912,
      "step": 6500
    },
    {
      "epoch": 1.9327235172617292,
      "grad_norm": 45.79448318481445,
      "learning_rate": 6.963706107996459e-07,
      "loss": 0.1001,
      "step": 6550
    },
    {
      "epoch": 1.947477131897315,
      "grad_norm": 71.29540252685547,
      "learning_rate": 5.488344644437887e-07,
      "loss": 0.088,
      "step": 6600
    },
    {
      "epoch": 1.9622307465329005,
      "grad_norm": 24.094072341918945,
      "learning_rate": 4.0129831808793156e-07,
      "loss": 0.1056,
      "step": 6650
    },
    {
      "epoch": 1.9769843611684863,
      "grad_norm": 36.936397552490234,
      "learning_rate": 2.537621717320744e-07,
      "loss": 0.1011,
      "step": 6700
    },
    {
      "epoch": 1.9917379758040719,
      "grad_norm": 67.30567932128906,
      "learning_rate": 1.0622602537621719e-07,
      "loss": 0.082,
      "step": 6750
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9563661847152553,
      "eval_f1": 0.9397381692221486,
      "eval_loss": 0.1370946168899536,
      "eval_precision": 0.9515164018980813,
      "eval_recall": 0.9282479621616182,
      "eval_runtime": 66.9594,
      "eval_samples_per_second": 404.902,
      "eval_steps_per_second": 12.664,
      "step": 6778
    }
  ],
  "logging_steps": 50,
  "max_steps": 6778,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1295802873630720.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
