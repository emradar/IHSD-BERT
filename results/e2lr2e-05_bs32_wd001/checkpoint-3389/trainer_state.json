{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3389,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014753614635585718,
      "grad_norm": 23.847089767456055,
      "learning_rate": 1.9861316022425495e-05,
      "loss": 0.5318,
      "step": 50
    },
    {
      "epoch": 0.029507229271171435,
      "grad_norm": 26.378890991210938,
      "learning_rate": 1.971377987606964e-05,
      "loss": 0.4029,
      "step": 100
    },
    {
      "epoch": 0.04426084390675716,
      "grad_norm": 40.67231369018555,
      "learning_rate": 1.956624372971378e-05,
      "loss": 0.3574,
      "step": 150
    },
    {
      "epoch": 0.05901445854234287,
      "grad_norm": 14.73836898803711,
      "learning_rate": 1.9418707583357927e-05,
      "loss": 0.3345,
      "step": 200
    },
    {
      "epoch": 0.07376807317792859,
      "grad_norm": 12.398255348205566,
      "learning_rate": 1.927117143700207e-05,
      "loss": 0.3347,
      "step": 250
    },
    {
      "epoch": 0.08852168781351431,
      "grad_norm": 12.978330612182617,
      "learning_rate": 1.912363529064621e-05,
      "loss": 0.3216,
      "step": 300
    },
    {
      "epoch": 0.10327530244910003,
      "grad_norm": 59.53179168701172,
      "learning_rate": 1.897904986721747e-05,
      "loss": 0.3063,
      "step": 350
    },
    {
      "epoch": 0.11802891708468574,
      "grad_norm": 30.771419525146484,
      "learning_rate": 1.883446444378873e-05,
      "loss": 0.3029,
      "step": 400
    },
    {
      "epoch": 0.13278253172027146,
      "grad_norm": 11.63904094696045,
      "learning_rate": 1.8686928297432874e-05,
      "loss": 0.3001,
      "step": 450
    },
    {
      "epoch": 0.14753614635585718,
      "grad_norm": 21.82642364501953,
      "learning_rate": 1.8539392151077016e-05,
      "loss": 0.2694,
      "step": 500
    },
    {
      "epoch": 0.1622897609914429,
      "grad_norm": 15.971054077148438,
      "learning_rate": 1.8391856004721157e-05,
      "loss": 0.2887,
      "step": 550
    },
    {
      "epoch": 0.17704337562702863,
      "grad_norm": 11.661199569702148,
      "learning_rate": 1.82443198583653e-05,
      "loss": 0.2692,
      "step": 600
    },
    {
      "epoch": 0.19179699026261435,
      "grad_norm": 21.022140502929688,
      "learning_rate": 1.8096783712009444e-05,
      "loss": 0.2804,
      "step": 650
    },
    {
      "epoch": 0.20655060489820007,
      "grad_norm": 11.852729797363281,
      "learning_rate": 1.7952198288580705e-05,
      "loss": 0.293,
      "step": 700
    },
    {
      "epoch": 0.2213042195337858,
      "grad_norm": 9.042975425720215,
      "learning_rate": 1.7804662142224847e-05,
      "loss": 0.2743,
      "step": 750
    },
    {
      "epoch": 0.23605783416937148,
      "grad_norm": 20.081932067871094,
      "learning_rate": 1.765712599586899e-05,
      "loss": 0.2829,
      "step": 800
    },
    {
      "epoch": 0.2508114488049572,
      "grad_norm": 15.7952241897583,
      "learning_rate": 1.750958984951313e-05,
      "loss": 0.2809,
      "step": 850
    },
    {
      "epoch": 0.2655650634405429,
      "grad_norm": 21.543550491333008,
      "learning_rate": 1.7362053703157275e-05,
      "loss": 0.304,
      "step": 900
    },
    {
      "epoch": 0.28031867807612865,
      "grad_norm": 32.04381561279297,
      "learning_rate": 1.7214517556801417e-05,
      "loss": 0.2811,
      "step": 950
    },
    {
      "epoch": 0.29507229271171437,
      "grad_norm": 14.85956859588623,
      "learning_rate": 1.706698141044556e-05,
      "loss": 0.2879,
      "step": 1000
    },
    {
      "epoch": 0.3098259073473001,
      "grad_norm": 19.77912712097168,
      "learning_rate": 1.6919445264089703e-05,
      "loss": 0.2432,
      "step": 1050
    },
    {
      "epoch": 0.3245795219828858,
      "grad_norm": 36.701576232910156,
      "learning_rate": 1.6771909117733845e-05,
      "loss": 0.2723,
      "step": 1100
    },
    {
      "epoch": 0.33933313661847153,
      "grad_norm": 14.142216682434082,
      "learning_rate": 1.662437297137799e-05,
      "loss": 0.2824,
      "step": 1150
    },
    {
      "epoch": 0.35408675125405725,
      "grad_norm": 19.05000114440918,
      "learning_rate": 1.6476836825022132e-05,
      "loss": 0.2777,
      "step": 1200
    },
    {
      "epoch": 0.368840365889643,
      "grad_norm": 11.194072723388672,
      "learning_rate": 1.6329300678666277e-05,
      "loss": 0.3015,
      "step": 1250
    },
    {
      "epoch": 0.3835939805252287,
      "grad_norm": 18.244022369384766,
      "learning_rate": 1.618176453231042e-05,
      "loss": 0.2822,
      "step": 1300
    },
    {
      "epoch": 0.3983475951608144,
      "grad_norm": 37.646297454833984,
      "learning_rate": 1.603422838595456e-05,
      "loss": 0.2742,
      "step": 1350
    },
    {
      "epoch": 0.41310120979640014,
      "grad_norm": 13.621655464172363,
      "learning_rate": 1.5886692239598702e-05,
      "loss": 0.273,
      "step": 1400
    },
    {
      "epoch": 0.42785482443198586,
      "grad_norm": 8.834137916564941,
      "learning_rate": 1.5739156093242847e-05,
      "loss": 0.2705,
      "step": 1450
    },
    {
      "epoch": 0.4426084390675716,
      "grad_norm": 19.128536224365234,
      "learning_rate": 1.559161994688699e-05,
      "loss": 0.2717,
      "step": 1500
    },
    {
      "epoch": 0.4573620537031573,
      "grad_norm": 21.617244720458984,
      "learning_rate": 1.544408380053113e-05,
      "loss": 0.2544,
      "step": 1550
    },
    {
      "epoch": 0.47211566833874297,
      "grad_norm": 11.765403747558594,
      "learning_rate": 1.5296547654175272e-05,
      "loss": 0.2593,
      "step": 1600
    },
    {
      "epoch": 0.4868692829743287,
      "grad_norm": 6.82732629776001,
      "learning_rate": 1.5149011507819418e-05,
      "loss": 0.2661,
      "step": 1650
    },
    {
      "epoch": 0.5016228976099144,
      "grad_norm": 12.997520446777344,
      "learning_rate": 1.500147536146356e-05,
      "loss": 0.2444,
      "step": 1700
    },
    {
      "epoch": 0.5163765122455002,
      "grad_norm": 19.3341007232666,
      "learning_rate": 1.4853939215107702e-05,
      "loss": 0.2608,
      "step": 1750
    },
    {
      "epoch": 0.5311301268810859,
      "grad_norm": 8.841188430786133,
      "learning_rate": 1.4706403068751845e-05,
      "loss": 0.2401,
      "step": 1800
    },
    {
      "epoch": 0.5458837415166716,
      "grad_norm": 15.83041000366211,
      "learning_rate": 1.4558866922395988e-05,
      "loss": 0.2501,
      "step": 1850
    },
    {
      "epoch": 0.5606373561522573,
      "grad_norm": 7.780704021453857,
      "learning_rate": 1.4411330776040132e-05,
      "loss": 0.2652,
      "step": 1900
    },
    {
      "epoch": 0.5753909707878431,
      "grad_norm": 38.97016143798828,
      "learning_rate": 1.4263794629684273e-05,
      "loss": 0.2685,
      "step": 1950
    },
    {
      "epoch": 0.5901445854234287,
      "grad_norm": 18.452743530273438,
      "learning_rate": 1.4119209206255533e-05,
      "loss": 0.2536,
      "step": 2000
    },
    {
      "epoch": 0.6048982000590145,
      "grad_norm": 12.708842277526855,
      "learning_rate": 1.3971673059899678e-05,
      "loss": 0.2326,
      "step": 2050
    },
    {
      "epoch": 0.6196518146946002,
      "grad_norm": 11.039215087890625,
      "learning_rate": 1.382413691354382e-05,
      "loss": 0.2267,
      "step": 2100
    },
    {
      "epoch": 0.6344054293301858,
      "grad_norm": 18.69455337524414,
      "learning_rate": 1.3676600767187961e-05,
      "loss": 0.2565,
      "step": 2150
    },
    {
      "epoch": 0.6491590439657716,
      "grad_norm": 9.265626907348633,
      "learning_rate": 1.3529064620832105e-05,
      "loss": 0.2339,
      "step": 2200
    },
    {
      "epoch": 0.6639126586013573,
      "grad_norm": 12.750293731689453,
      "learning_rate": 1.3381528474476248e-05,
      "loss": 0.2378,
      "step": 2250
    },
    {
      "epoch": 0.6786662732369431,
      "grad_norm": 8.139863014221191,
      "learning_rate": 1.3233992328120391e-05,
      "loss": 0.2208,
      "step": 2300
    },
    {
      "epoch": 0.6934198878725287,
      "grad_norm": 18.951311111450195,
      "learning_rate": 1.3086456181764533e-05,
      "loss": 0.2025,
      "step": 2350
    },
    {
      "epoch": 0.7081735025081145,
      "grad_norm": 8.20529842376709,
      "learning_rate": 1.2938920035408675e-05,
      "loss": 0.2367,
      "step": 2400
    },
    {
      "epoch": 0.7229271171437002,
      "grad_norm": 11.86007022857666,
      "learning_rate": 1.279138388905282e-05,
      "loss": 0.2345,
      "step": 2450
    },
    {
      "epoch": 0.737680731779286,
      "grad_norm": 8.465018272399902,
      "learning_rate": 1.2643847742696961e-05,
      "loss": 0.2111,
      "step": 2500
    },
    {
      "epoch": 0.7524343464148716,
      "grad_norm": 20.673715591430664,
      "learning_rate": 1.2496311596341105e-05,
      "loss": 0.2205,
      "step": 2550
    },
    {
      "epoch": 0.7671879610504574,
      "grad_norm": 10.271485328674316,
      "learning_rate": 1.2348775449985246e-05,
      "loss": 0.2152,
      "step": 2600
    },
    {
      "epoch": 0.7819415756860431,
      "grad_norm": 10.810853958129883,
      "learning_rate": 1.2201239303629391e-05,
      "loss": 0.2294,
      "step": 2650
    },
    {
      "epoch": 0.7966951903216288,
      "grad_norm": 16.553739547729492,
      "learning_rate": 1.2053703157273533e-05,
      "loss": 0.2553,
      "step": 2700
    },
    {
      "epoch": 0.8114488049572145,
      "grad_norm": 6.733879089355469,
      "learning_rate": 1.1906167010917675e-05,
      "loss": 0.2112,
      "step": 2750
    },
    {
      "epoch": 0.8262024195928003,
      "grad_norm": 16.00786018371582,
      "learning_rate": 1.175863086456182e-05,
      "loss": 0.2175,
      "step": 2800
    },
    {
      "epoch": 0.8409560342283859,
      "grad_norm": 10.475824356079102,
      "learning_rate": 1.1611094718205961e-05,
      "loss": 0.2146,
      "step": 2850
    },
    {
      "epoch": 0.8557096488639717,
      "grad_norm": 22.089696884155273,
      "learning_rate": 1.1463558571850105e-05,
      "loss": 0.2119,
      "step": 2900
    },
    {
      "epoch": 0.8704632634995574,
      "grad_norm": 15.649863243103027,
      "learning_rate": 1.1316022425494246e-05,
      "loss": 0.2234,
      "step": 2950
    },
    {
      "epoch": 0.8852168781351432,
      "grad_norm": 18.604509353637695,
      "learning_rate": 1.1168486279138391e-05,
      "loss": 0.224,
      "step": 3000
    },
    {
      "epoch": 0.8999704927707288,
      "grad_norm": 12.458653450012207,
      "learning_rate": 1.1020950132782533e-05,
      "loss": 0.2113,
      "step": 3050
    },
    {
      "epoch": 0.9147241074063146,
      "grad_norm": 17.02798080444336,
      "learning_rate": 1.0873413986426675e-05,
      "loss": 0.2363,
      "step": 3100
    },
    {
      "epoch": 0.9294777220419003,
      "grad_norm": 20.60870933532715,
      "learning_rate": 1.0725877840070818e-05,
      "loss": 0.2055,
      "step": 3150
    },
    {
      "epoch": 0.9442313366774859,
      "grad_norm": 19.62511444091797,
      "learning_rate": 1.0578341693714961e-05,
      "loss": 0.2036,
      "step": 3200
    },
    {
      "epoch": 0.9589849513130717,
      "grad_norm": 6.520667552947998,
      "learning_rate": 1.0430805547359105e-05,
      "loss": 0.1995,
      "step": 3250
    },
    {
      "epoch": 0.9737385659486574,
      "grad_norm": 17.304393768310547,
      "learning_rate": 1.0283269401003246e-05,
      "loss": 0.2087,
      "step": 3300
    },
    {
      "epoch": 0.9884921805842432,
      "grad_norm": 28.82863998413086,
      "learning_rate": 1.0135733254647388e-05,
      "loss": 0.179,
      "step": 3350
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9074948362348776,
      "eval_f1": 0.863843648208469,
      "eval_loss": 0.2079961746931076,
      "eval_precision": 0.9378757515030061,
      "eval_recall": 0.8006440575626447,
      "eval_runtime": 67.1928,
      "eval_samples_per_second": 403.495,
      "eval_steps_per_second": 12.62,
      "step": 3389
    }
  ],
  "logging_steps": 50,
  "max_steps": 6778,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 647901436815360.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
