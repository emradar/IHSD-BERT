{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 10167,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014753614635585718,
      "grad_norm": 31.07817268371582,
      "learning_rate": 1.990754401495033e-05,
      "loss": 0.5512,
      "step": 50
    },
    {
      "epoch": 0.029507229271171435,
      "grad_norm": 54.651329040527344,
      "learning_rate": 1.9811153732664505e-05,
      "loss": 0.4186,
      "step": 100
    },
    {
      "epoch": 0.04426084390675716,
      "grad_norm": 78.93470001220703,
      "learning_rate": 1.971476345037868e-05,
      "loss": 0.3518,
      "step": 150
    },
    {
      "epoch": 0.05901445854234287,
      "grad_norm": 17.76141929626465,
      "learning_rate": 1.962034031671093e-05,
      "loss": 0.5297,
      "step": 200
    },
    {
      "epoch": 0.07376807317792859,
      "grad_norm": 16.33285140991211,
      "learning_rate": 1.9521982885807023e-05,
      "loss": 0.42,
      "step": 250
    },
    {
      "epoch": 0.08852168781351431,
      "grad_norm": 12.575055122375488,
      "learning_rate": 1.942362545490312e-05,
      "loss": 0.3745,
      "step": 300
    },
    {
      "epoch": 0.10327530244910003,
      "grad_norm": 14.98082160949707,
      "learning_rate": 1.9325268023999217e-05,
      "loss": 0.3193,
      "step": 350
    },
    {
      "epoch": 0.11802891708468574,
      "grad_norm": 18.271108627319336,
      "learning_rate": 1.922691059309531e-05,
      "loss": 0.3121,
      "step": 400
    },
    {
      "epoch": 0.13278253172027146,
      "grad_norm": 12.483625411987305,
      "learning_rate": 1.9128553162191407e-05,
      "loss": 0.2898,
      "step": 450
    },
    {
      "epoch": 0.14753614635585718,
      "grad_norm": 19.178787231445312,
      "learning_rate": 1.90301957312875e-05,
      "loss": 0.2806,
      "step": 500
    },
    {
      "epoch": 0.1622897609914429,
      "grad_norm": 22.031824111938477,
      "learning_rate": 1.8931838300383597e-05,
      "loss": 0.3004,
      "step": 550
    },
    {
      "epoch": 0.17704337562702863,
      "grad_norm": 15.35480785369873,
      "learning_rate": 1.883348086947969e-05,
      "loss": 0.2822,
      "step": 600
    },
    {
      "epoch": 0.19179699026261435,
      "grad_norm": 22.09703254699707,
      "learning_rate": 1.8735123438575787e-05,
      "loss": 0.2773,
      "step": 650
    },
    {
      "epoch": 0.20655060489820007,
      "grad_norm": 7.130805015563965,
      "learning_rate": 1.863676600767188e-05,
      "loss": 0.2916,
      "step": 700
    },
    {
      "epoch": 0.2213042195337858,
      "grad_norm": 24.313947677612305,
      "learning_rate": 1.8538408576767977e-05,
      "loss": 0.2809,
      "step": 750
    },
    {
      "epoch": 0.23605783416937148,
      "grad_norm": 30.2020320892334,
      "learning_rate": 1.844005114586407e-05,
      "loss": 0.2912,
      "step": 800
    },
    {
      "epoch": 0.2508114488049572,
      "grad_norm": 12.543693542480469,
      "learning_rate": 1.8341693714960167e-05,
      "loss": 0.2709,
      "step": 850
    },
    {
      "epoch": 0.2655650634405429,
      "grad_norm": 14.975255012512207,
      "learning_rate": 1.824333628405626e-05,
      "loss": 0.2975,
      "step": 900
    },
    {
      "epoch": 0.28031867807612865,
      "grad_norm": 7.466927528381348,
      "learning_rate": 1.8144978853152357e-05,
      "loss": 0.2719,
      "step": 950
    },
    {
      "epoch": 0.29507229271171437,
      "grad_norm": 11.507939338684082,
      "learning_rate": 1.804662142224845e-05,
      "loss": 0.2922,
      "step": 1000
    },
    {
      "epoch": 0.3098259073473001,
      "grad_norm": 8.784261703491211,
      "learning_rate": 1.7948263991344547e-05,
      "loss": 0.2491,
      "step": 1050
    },
    {
      "epoch": 0.3245795219828858,
      "grad_norm": 6.340132713317871,
      "learning_rate": 1.7849906560440644e-05,
      "loss": 0.2805,
      "step": 1100
    },
    {
      "epoch": 0.33933313661847153,
      "grad_norm": 8.87680721282959,
      "learning_rate": 1.7751549129536737e-05,
      "loss": 0.2733,
      "step": 1150
    },
    {
      "epoch": 0.35408675125405725,
      "grad_norm": 19.33877182006836,
      "learning_rate": 1.7653191698632834e-05,
      "loss": 0.2855,
      "step": 1200
    },
    {
      "epoch": 0.368840365889643,
      "grad_norm": 8.292648315429688,
      "learning_rate": 1.7554834267728927e-05,
      "loss": 0.2842,
      "step": 1250
    },
    {
      "epoch": 0.3835939805252287,
      "grad_norm": 33.092864990234375,
      "learning_rate": 1.7456476836825024e-05,
      "loss": 0.2689,
      "step": 1300
    },
    {
      "epoch": 0.3983475951608144,
      "grad_norm": 23.528060913085938,
      "learning_rate": 1.735811940592112e-05,
      "loss": 0.2558,
      "step": 1350
    },
    {
      "epoch": 0.41310120979640014,
      "grad_norm": 27.110416412353516,
      "learning_rate": 1.7259761975017214e-05,
      "loss": 0.2635,
      "step": 1400
    },
    {
      "epoch": 0.42785482443198586,
      "grad_norm": 7.174333095550537,
      "learning_rate": 1.716140454411331e-05,
      "loss": 0.27,
      "step": 1450
    },
    {
      "epoch": 0.4426084390675716,
      "grad_norm": 18.488903045654297,
      "learning_rate": 1.7063047113209404e-05,
      "loss": 0.2755,
      "step": 1500
    },
    {
      "epoch": 0.4573620537031573,
      "grad_norm": 19.817773818969727,
      "learning_rate": 1.69646896823055e-05,
      "loss": 0.2515,
      "step": 1550
    },
    {
      "epoch": 0.47211566833874297,
      "grad_norm": 16.30522346496582,
      "learning_rate": 1.6866332251401594e-05,
      "loss": 0.2841,
      "step": 1600
    },
    {
      "epoch": 0.4868692829743287,
      "grad_norm": 6.233822822570801,
      "learning_rate": 1.676797482049769e-05,
      "loss": 0.2546,
      "step": 1650
    },
    {
      "epoch": 0.5016228976099144,
      "grad_norm": 20.555944442749023,
      "learning_rate": 1.6669617389593787e-05,
      "loss": 0.2456,
      "step": 1700
    },
    {
      "epoch": 0.5163765122455002,
      "grad_norm": 9.471553802490234,
      "learning_rate": 1.657125995868988e-05,
      "loss": 0.2488,
      "step": 1750
    },
    {
      "epoch": 0.5311301268810859,
      "grad_norm": 8.942400932312012,
      "learning_rate": 1.6472902527785977e-05,
      "loss": 0.2418,
      "step": 1800
    },
    {
      "epoch": 0.5458837415166716,
      "grad_norm": 5.567537784576416,
      "learning_rate": 1.637454509688207e-05,
      "loss": 0.2367,
      "step": 1850
    },
    {
      "epoch": 0.5606373561522573,
      "grad_norm": 8.394820213317871,
      "learning_rate": 1.6276187665978167e-05,
      "loss": 0.2704,
      "step": 1900
    },
    {
      "epoch": 0.5753909707878431,
      "grad_norm": 9.561812400817871,
      "learning_rate": 1.617783023507426e-05,
      "loss": 0.2561,
      "step": 1950
    },
    {
      "epoch": 0.5901445854234287,
      "grad_norm": 25.923433303833008,
      "learning_rate": 1.6079472804170357e-05,
      "loss": 0.2461,
      "step": 2000
    },
    {
      "epoch": 0.6048982000590145,
      "grad_norm": 7.004174709320068,
      "learning_rate": 1.598111537326645e-05,
      "loss": 0.2242,
      "step": 2050
    },
    {
      "epoch": 0.6196518146946002,
      "grad_norm": 14.083045959472656,
      "learning_rate": 1.5882757942362547e-05,
      "loss": 0.2307,
      "step": 2100
    },
    {
      "epoch": 0.6344054293301858,
      "grad_norm": 21.999475479125977,
      "learning_rate": 1.578440051145864e-05,
      "loss": 0.2634,
      "step": 2150
    },
    {
      "epoch": 0.6491590439657716,
      "grad_norm": 9.260176658630371,
      "learning_rate": 1.5686043080554737e-05,
      "loss": 0.2382,
      "step": 2200
    },
    {
      "epoch": 0.6639126586013573,
      "grad_norm": 12.044564247131348,
      "learning_rate": 1.5587685649650834e-05,
      "loss": 0.2195,
      "step": 2250
    },
    {
      "epoch": 0.6786662732369431,
      "grad_norm": 10.693504333496094,
      "learning_rate": 1.5489328218746927e-05,
      "loss": 0.2194,
      "step": 2300
    },
    {
      "epoch": 0.6934198878725287,
      "grad_norm": 22.205249786376953,
      "learning_rate": 1.5390970787843024e-05,
      "loss": 0.2038,
      "step": 2350
    },
    {
      "epoch": 0.7081735025081145,
      "grad_norm": 10.317129135131836,
      "learning_rate": 1.529261335693912e-05,
      "loss": 0.2371,
      "step": 2400
    },
    {
      "epoch": 0.7229271171437002,
      "grad_norm": 19.35365867614746,
      "learning_rate": 1.5194255926035214e-05,
      "loss": 0.2327,
      "step": 2450
    },
    {
      "epoch": 0.737680731779286,
      "grad_norm": 9.85568904876709,
      "learning_rate": 1.5095898495131309e-05,
      "loss": 0.2131,
      "step": 2500
    },
    {
      "epoch": 0.7524343464148716,
      "grad_norm": 12.953634262084961,
      "learning_rate": 1.4997541064227404e-05,
      "loss": 0.2194,
      "step": 2550
    },
    {
      "epoch": 0.7671879610504574,
      "grad_norm": 7.447958946228027,
      "learning_rate": 1.48991836333235e-05,
      "loss": 0.2214,
      "step": 2600
    },
    {
      "epoch": 0.7819415756860431,
      "grad_norm": 17.86975860595703,
      "learning_rate": 1.4800826202419594e-05,
      "loss": 0.2213,
      "step": 2650
    },
    {
      "epoch": 0.7966951903216288,
      "grad_norm": 10.476585388183594,
      "learning_rate": 1.470246877151569e-05,
      "loss": 0.2525,
      "step": 2700
    },
    {
      "epoch": 0.8114488049572145,
      "grad_norm": 9.842999458312988,
      "learning_rate": 1.4604111340611784e-05,
      "loss": 0.2151,
      "step": 2750
    },
    {
      "epoch": 0.8262024195928003,
      "grad_norm": 10.4342679977417,
      "learning_rate": 1.450575390970788e-05,
      "loss": 0.2082,
      "step": 2800
    },
    {
      "epoch": 0.8409560342283859,
      "grad_norm": 12.180743217468262,
      "learning_rate": 1.4407396478803974e-05,
      "loss": 0.214,
      "step": 2850
    },
    {
      "epoch": 0.8557096488639717,
      "grad_norm": 8.716874122619629,
      "learning_rate": 1.430903904790007e-05,
      "loss": 0.2129,
      "step": 2900
    },
    {
      "epoch": 0.8704632634995574,
      "grad_norm": 18.98058319091797,
      "learning_rate": 1.4210681616996165e-05,
      "loss": 0.2336,
      "step": 2950
    },
    {
      "epoch": 0.8852168781351432,
      "grad_norm": 12.502464294433594,
      "learning_rate": 1.411232418609226e-05,
      "loss": 0.23,
      "step": 3000
    },
    {
      "epoch": 0.8999704927707288,
      "grad_norm": 12.926324844360352,
      "learning_rate": 1.4013966755188355e-05,
      "loss": 0.2112,
      "step": 3050
    },
    {
      "epoch": 0.9147241074063146,
      "grad_norm": 26.705842971801758,
      "learning_rate": 1.3915609324284452e-05,
      "loss": 0.2198,
      "step": 3100
    },
    {
      "epoch": 0.9294777220419003,
      "grad_norm": 22.545534133911133,
      "learning_rate": 1.3817251893380545e-05,
      "loss": 0.206,
      "step": 3150
    },
    {
      "epoch": 0.9442313366774859,
      "grad_norm": 10.489611625671387,
      "learning_rate": 1.3718894462476642e-05,
      "loss": 0.2094,
      "step": 3200
    },
    {
      "epoch": 0.9589849513130717,
      "grad_norm": 11.441422462463379,
      "learning_rate": 1.3620537031572735e-05,
      "loss": 0.1937,
      "step": 3250
    },
    {
      "epoch": 0.9737385659486574,
      "grad_norm": 16.546701431274414,
      "learning_rate": 1.3522179600668832e-05,
      "loss": 0.2066,
      "step": 3300
    },
    {
      "epoch": 0.9884921805842432,
      "grad_norm": 17.545015335083008,
      "learning_rate": 1.3423822169764927e-05,
      "loss": 0.1974,
      "step": 3350
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.905908822661552,
      "eval_f1": 0.8597195490789112,
      "eval_loss": 0.22300392389297485,
      "eval_precision": 0.94774490785645,
      "eval_recall": 0.7866559323739559,
      "eval_runtime": 70.0794,
      "eval_samples_per_second": 386.875,
      "eval_steps_per_second": 12.101,
      "step": 3389
    },
    {
      "epoch": 1.0032457952198288,
      "grad_norm": 15.755697250366211,
      "learning_rate": 1.3325464738861022e-05,
      "loss": 0.2045,
      "step": 3400
    },
    {
      "epoch": 1.0179994098554146,
      "grad_norm": 3.3863396644592285,
      "learning_rate": 1.3227107307957117e-05,
      "loss": 0.1716,
      "step": 3450
    },
    {
      "epoch": 1.0327530244910004,
      "grad_norm": 34.83467102050781,
      "learning_rate": 1.3128749877053214e-05,
      "loss": 0.1433,
      "step": 3500
    },
    {
      "epoch": 1.047506639126586,
      "grad_norm": 21.67413330078125,
      "learning_rate": 1.3030392446149307e-05,
      "loss": 0.159,
      "step": 3550
    },
    {
      "epoch": 1.0622602537621717,
      "grad_norm": 14.21854305267334,
      "learning_rate": 1.2932035015245404e-05,
      "loss": 0.1478,
      "step": 3600
    },
    {
      "epoch": 1.0770138683977575,
      "grad_norm": 6.923311233520508,
      "learning_rate": 1.2833677584341497e-05,
      "loss": 0.1568,
      "step": 3650
    },
    {
      "epoch": 1.0917674830333433,
      "grad_norm": 35.901798248291016,
      "learning_rate": 1.2735320153437594e-05,
      "loss": 0.1413,
      "step": 3700
    },
    {
      "epoch": 1.1065210976689288,
      "grad_norm": 21.74582290649414,
      "learning_rate": 1.2636962722533687e-05,
      "loss": 0.1583,
      "step": 3750
    },
    {
      "epoch": 1.1212747123045146,
      "grad_norm": 24.227041244506836,
      "learning_rate": 1.2538605291629784e-05,
      "loss": 0.1644,
      "step": 3800
    },
    {
      "epoch": 1.1360283269401004,
      "grad_norm": 4.13705587387085,
      "learning_rate": 1.2440247860725879e-05,
      "loss": 0.1508,
      "step": 3850
    },
    {
      "epoch": 1.1507819415756861,
      "grad_norm": 14.002213478088379,
      "learning_rate": 1.2341890429821974e-05,
      "loss": 0.1664,
      "step": 3900
    },
    {
      "epoch": 1.1655355562112717,
      "grad_norm": 21.85146141052246,
      "learning_rate": 1.2243532998918069e-05,
      "loss": 0.1381,
      "step": 3950
    },
    {
      "epoch": 1.1802891708468575,
      "grad_norm": 10.554089546203613,
      "learning_rate": 1.2145175568014165e-05,
      "loss": 0.1564,
      "step": 4000
    },
    {
      "epoch": 1.1950427854824432,
      "grad_norm": 19.711305618286133,
      "learning_rate": 1.2046818137110259e-05,
      "loss": 0.1779,
      "step": 4050
    },
    {
      "epoch": 1.2097964001180288,
      "grad_norm": 32.42538070678711,
      "learning_rate": 1.1948460706206355e-05,
      "loss": 0.144,
      "step": 4100
    },
    {
      "epoch": 1.2245500147536146,
      "grad_norm": 26.249252319335938,
      "learning_rate": 1.1850103275302449e-05,
      "loss": 0.1475,
      "step": 4150
    },
    {
      "epoch": 1.2393036293892004,
      "grad_norm": 5.850816249847412,
      "learning_rate": 1.1751745844398545e-05,
      "loss": 0.1471,
      "step": 4200
    },
    {
      "epoch": 1.2540572440247861,
      "grad_norm": 37.14395523071289,
      "learning_rate": 1.1653388413494639e-05,
      "loss": 0.1436,
      "step": 4250
    },
    {
      "epoch": 1.268810858660372,
      "grad_norm": 7.201254844665527,
      "learning_rate": 1.1555030982590735e-05,
      "loss": 0.135,
      "step": 4300
    },
    {
      "epoch": 1.2835644732959575,
      "grad_norm": 43.340545654296875,
      "learning_rate": 1.145667355168683e-05,
      "loss": 0.1468,
      "step": 4350
    },
    {
      "epoch": 1.2983180879315432,
      "grad_norm": 39.67958068847656,
      "learning_rate": 1.1358316120782925e-05,
      "loss": 0.1434,
      "step": 4400
    },
    {
      "epoch": 1.313071702567129,
      "grad_norm": 20.341785430908203,
      "learning_rate": 1.125995868987902e-05,
      "loss": 0.1587,
      "step": 4450
    },
    {
      "epoch": 1.3278253172027146,
      "grad_norm": 36.573184967041016,
      "learning_rate": 1.1161601258975117e-05,
      "loss": 0.1435,
      "step": 4500
    },
    {
      "epoch": 1.3425789318383003,
      "grad_norm": 19.420547485351562,
      "learning_rate": 1.106324382807121e-05,
      "loss": 0.1415,
      "step": 4550
    },
    {
      "epoch": 1.3573325464738861,
      "grad_norm": 17.504722595214844,
      "learning_rate": 1.0964886397167307e-05,
      "loss": 0.1214,
      "step": 4600
    },
    {
      "epoch": 1.372086161109472,
      "grad_norm": 32.3795166015625,
      "learning_rate": 1.08665289662634e-05,
      "loss": 0.1312,
      "step": 4650
    },
    {
      "epoch": 1.3868397757450575,
      "grad_norm": 22.867374420166016,
      "learning_rate": 1.0768171535359497e-05,
      "loss": 0.1347,
      "step": 4700
    },
    {
      "epoch": 1.4015933903806432,
      "grad_norm": 14.271947860717773,
      "learning_rate": 1.0669814104455592e-05,
      "loss": 0.1628,
      "step": 4750
    },
    {
      "epoch": 1.416347005016229,
      "grad_norm": 20.20940589904785,
      "learning_rate": 1.0571456673551687e-05,
      "loss": 0.1517,
      "step": 4800
    },
    {
      "epoch": 1.4311006196518146,
      "grad_norm": 23.3306884765625,
      "learning_rate": 1.0473099242647784e-05,
      "loss": 0.1413,
      "step": 4850
    },
    {
      "epoch": 1.4458542342874003,
      "grad_norm": 5.9206037521362305,
      "learning_rate": 1.0374741811743879e-05,
      "loss": 0.1219,
      "step": 4900
    },
    {
      "epoch": 1.4606078489229861,
      "grad_norm": 11.064217567443848,
      "learning_rate": 1.0276384380839974e-05,
      "loss": 0.1273,
      "step": 4950
    },
    {
      "epoch": 1.475361463558572,
      "grad_norm": 35.53218078613281,
      "learning_rate": 1.0178026949936069e-05,
      "loss": 0.1458,
      "step": 5000
    },
    {
      "epoch": 1.4901150781941577,
      "grad_norm": 18.967979431152344,
      "learning_rate": 1.0079669519032166e-05,
      "loss": 0.1422,
      "step": 5050
    },
    {
      "epoch": 1.5048686928297434,
      "grad_norm": 6.636789321899414,
      "learning_rate": 9.981312088128259e-06,
      "loss": 0.1266,
      "step": 5100
    },
    {
      "epoch": 1.519622307465329,
      "grad_norm": 34.140098571777344,
      "learning_rate": 9.882954657224354e-06,
      "loss": 0.1216,
      "step": 5150
    },
    {
      "epoch": 1.5343759221009146,
      "grad_norm": 17.19265365600586,
      "learning_rate": 9.784597226320449e-06,
      "loss": 0.1509,
      "step": 5200
    },
    {
      "epoch": 1.5491295367365003,
      "grad_norm": 46.98081970214844,
      "learning_rate": 9.686239795416544e-06,
      "loss": 0.1275,
      "step": 5250
    },
    {
      "epoch": 1.5638831513720861,
      "grad_norm": 32.2158203125,
      "learning_rate": 9.587882364512639e-06,
      "loss": 0.1045,
      "step": 5300
    },
    {
      "epoch": 1.5786367660076719,
      "grad_norm": 75.59507751464844,
      "learning_rate": 9.489524933608736e-06,
      "loss": 0.1304,
      "step": 5350
    },
    {
      "epoch": 1.5933903806432577,
      "grad_norm": 54.36486053466797,
      "learning_rate": 9.39116750270483e-06,
      "loss": 0.1279,
      "step": 5400
    },
    {
      "epoch": 1.6081439952788434,
      "grad_norm": 14.406488418579102,
      "learning_rate": 9.292810071800926e-06,
      "loss": 0.1123,
      "step": 5450
    },
    {
      "epoch": 1.622897609914429,
      "grad_norm": 24.72789192199707,
      "learning_rate": 9.19445264089702e-06,
      "loss": 0.137,
      "step": 5500
    },
    {
      "epoch": 1.6376512245500148,
      "grad_norm": 17.703752517700195,
      "learning_rate": 9.096095209993116e-06,
      "loss": 0.1467,
      "step": 5550
    },
    {
      "epoch": 1.6524048391856003,
      "grad_norm": 3.012277841567993,
      "learning_rate": 8.99773777908921e-06,
      "loss": 0.0936,
      "step": 5600
    },
    {
      "epoch": 1.667158453821186,
      "grad_norm": 0.9620214104652405,
      "learning_rate": 8.899380348185306e-06,
      "loss": 0.1166,
      "step": 5650
    },
    {
      "epoch": 1.6819120684567719,
      "grad_norm": 17.663637161254883,
      "learning_rate": 8.8010229172814e-06,
      "loss": 0.1427,
      "step": 5700
    },
    {
      "epoch": 1.6966656830923577,
      "grad_norm": 8.815797805786133,
      "learning_rate": 8.702665486377496e-06,
      "loss": 0.1279,
      "step": 5750
    },
    {
      "epoch": 1.7114192977279434,
      "grad_norm": 10.686585426330566,
      "learning_rate": 8.60430805547359e-06,
      "loss": 0.1047,
      "step": 5800
    },
    {
      "epoch": 1.7261729123635292,
      "grad_norm": 3.1705682277679443,
      "learning_rate": 8.505950624569687e-06,
      "loss": 0.1287,
      "step": 5850
    },
    {
      "epoch": 1.7409265269991148,
      "grad_norm": 13.091301918029785,
      "learning_rate": 8.407593193665782e-06,
      "loss": 0.1266,
      "step": 5900
    },
    {
      "epoch": 1.7556801416347005,
      "grad_norm": 17.517995834350586,
      "learning_rate": 8.309235762761877e-06,
      "loss": 0.1155,
      "step": 5950
    },
    {
      "epoch": 1.770433756270286,
      "grad_norm": 30.572683334350586,
      "learning_rate": 8.210878331857972e-06,
      "loss": 0.1242,
      "step": 6000
    },
    {
      "epoch": 1.7851873709058719,
      "grad_norm": 4.6247382164001465,
      "learning_rate": 8.112520900954067e-06,
      "loss": 0.1312,
      "step": 6050
    },
    {
      "epoch": 1.7999409855414576,
      "grad_norm": 1.3492226600646973,
      "learning_rate": 8.014163470050162e-06,
      "loss": 0.1083,
      "step": 6100
    },
    {
      "epoch": 1.8146946001770434,
      "grad_norm": 18.03180694580078,
      "learning_rate": 7.915806039146257e-06,
      "loss": 0.1315,
      "step": 6150
    },
    {
      "epoch": 1.8294482148126292,
      "grad_norm": 30.28909683227539,
      "learning_rate": 7.817448608242352e-06,
      "loss": 0.1165,
      "step": 6200
    },
    {
      "epoch": 1.8442018294482148,
      "grad_norm": 20.863521575927734,
      "learning_rate": 7.719091177338447e-06,
      "loss": 0.1268,
      "step": 6250
    },
    {
      "epoch": 1.8589554440838005,
      "grad_norm": 29.373048782348633,
      "learning_rate": 7.620733746434543e-06,
      "loss": 0.1162,
      "step": 6300
    },
    {
      "epoch": 1.873709058719386,
      "grad_norm": 35.801326751708984,
      "learning_rate": 7.522376315530638e-06,
      "loss": 0.104,
      "step": 6350
    },
    {
      "epoch": 1.8884626733549719,
      "grad_norm": 15.64318561553955,
      "learning_rate": 7.424018884626735e-06,
      "loss": 0.1267,
      "step": 6400
    },
    {
      "epoch": 1.9032162879905576,
      "grad_norm": 46.027687072753906,
      "learning_rate": 7.32566145372283e-06,
      "loss": 0.0928,
      "step": 6450
    },
    {
      "epoch": 1.9179699026261434,
      "grad_norm": 20.27109146118164,
      "learning_rate": 7.227304022818925e-06,
      "loss": 0.1033,
      "step": 6500
    },
    {
      "epoch": 1.9327235172617292,
      "grad_norm": 38.42678451538086,
      "learning_rate": 7.128946591915021e-06,
      "loss": 0.1169,
      "step": 6550
    },
    {
      "epoch": 1.947477131897315,
      "grad_norm": 21.95445442199707,
      "learning_rate": 7.030589161011116e-06,
      "loss": 0.096,
      "step": 6600
    },
    {
      "epoch": 1.9622307465329005,
      "grad_norm": 52.02153396606445,
      "learning_rate": 6.932231730107211e-06,
      "loss": 0.1107,
      "step": 6650
    },
    {
      "epoch": 1.9769843611684863,
      "grad_norm": 31.44765853881836,
      "learning_rate": 6.833874299203306e-06,
      "loss": 0.0938,
      "step": 6700
    },
    {
      "epoch": 1.9917379758040719,
      "grad_norm": 21.067127227783203,
      "learning_rate": 6.735516868299401e-06,
      "loss": 0.0906,
      "step": 6750
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9565137208616111,
      "eval_f1": 0.9399602790650303,
      "eval_loss": 0.14473509788513184,
      "eval_precision": 0.9514432989690722,
      "eval_recall": 0.9287511321324343,
      "eval_runtime": 70.7316,
      "eval_samples_per_second": 383.308,
      "eval_steps_per_second": 11.989,
      "step": 6778
    },
    {
      "epoch": 2.0064915904396576,
      "grad_norm": 1.5660667419433594,
      "learning_rate": 6.6371594373954965e-06,
      "loss": 0.083,
      "step": 6800
    },
    {
      "epoch": 2.0212452050752434,
      "grad_norm": 1.1526795625686646,
      "learning_rate": 6.5388020064915915e-06,
      "loss": 0.0776,
      "step": 6850
    },
    {
      "epoch": 2.035998819710829,
      "grad_norm": 5.122705459594727,
      "learning_rate": 6.4404445755876865e-06,
      "loss": 0.0598,
      "step": 6900
    },
    {
      "epoch": 2.050752434346415,
      "grad_norm": 23.79949378967285,
      "learning_rate": 6.3420871446837815e-06,
      "loss": 0.0768,
      "step": 6950
    },
    {
      "epoch": 2.0655060489820007,
      "grad_norm": 24.003538131713867,
      "learning_rate": 6.2437297137798765e-06,
      "loss": 0.07,
      "step": 7000
    },
    {
      "epoch": 2.0802596636175865,
      "grad_norm": 0.1687459945678711,
      "learning_rate": 6.145372282875972e-06,
      "loss": 0.0535,
      "step": 7050
    },
    {
      "epoch": 2.095013278253172,
      "grad_norm": 6.696930408477783,
      "learning_rate": 6.047014851972067e-06,
      "loss": 0.0544,
      "step": 7100
    },
    {
      "epoch": 2.1097668928887576,
      "grad_norm": 53.380672454833984,
      "learning_rate": 5.948657421068162e-06,
      "loss": 0.0647,
      "step": 7150
    },
    {
      "epoch": 2.1245205075243434,
      "grad_norm": 59.89360427856445,
      "learning_rate": 5.850299990164257e-06,
      "loss": 0.0636,
      "step": 7200
    },
    {
      "epoch": 2.139274122159929,
      "grad_norm": 2.1658976078033447,
      "learning_rate": 5.7539097078784314e-06,
      "loss": 0.0524,
      "step": 7250
    },
    {
      "epoch": 2.154027736795515,
      "grad_norm": 0.27635622024536133,
      "learning_rate": 5.6555522769745264e-06,
      "loss": 0.0364,
      "step": 7300
    },
    {
      "epoch": 2.1687813514311007,
      "grad_norm": 0.5346750617027283,
      "learning_rate": 5.5571948460706214e-06,
      "loss": 0.0587,
      "step": 7350
    },
    {
      "epoch": 2.1835349660666865,
      "grad_norm": 43.811851501464844,
      "learning_rate": 5.4588374151667164e-06,
      "loss": 0.059,
      "step": 7400
    },
    {
      "epoch": 2.198288580702272,
      "grad_norm": 91.14614868164062,
      "learning_rate": 5.360479984262812e-06,
      "loss": 0.0672,
      "step": 7450
    },
    {
      "epoch": 2.2130421953378576,
      "grad_norm": 0.17269255220890045,
      "learning_rate": 5.262122553358907e-06,
      "loss": 0.0554,
      "step": 7500
    },
    {
      "epoch": 2.2277958099734434,
      "grad_norm": 4.693750858306885,
      "learning_rate": 5.163765122455002e-06,
      "loss": 0.0534,
      "step": 7550
    },
    {
      "epoch": 2.242549424609029,
      "grad_norm": 6.261875152587891,
      "learning_rate": 5.065407691551097e-06,
      "loss": 0.0638,
      "step": 7600
    },
    {
      "epoch": 2.257303039244615,
      "grad_norm": 69.84395599365234,
      "learning_rate": 4.967050260647192e-06,
      "loss": 0.0513,
      "step": 7650
    },
    {
      "epoch": 2.2720566538802007,
      "grad_norm": 104.25554656982422,
      "learning_rate": 4.868692829743287e-06,
      "loss": 0.0692,
      "step": 7700
    },
    {
      "epoch": 2.2868102685157865,
      "grad_norm": 3.1174886226654053,
      "learning_rate": 4.770335398839382e-06,
      "loss": 0.0453,
      "step": 7750
    },
    {
      "epoch": 2.3015638831513723,
      "grad_norm": 0.036968573927879333,
      "learning_rate": 4.671977967935477e-06,
      "loss": 0.0338,
      "step": 7800
    },
    {
      "epoch": 2.3163174977869576,
      "grad_norm": 0.38113388419151306,
      "learning_rate": 4.573620537031573e-06,
      "loss": 0.0673,
      "step": 7850
    },
    {
      "epoch": 2.3310711124225434,
      "grad_norm": 163.6351318359375,
      "learning_rate": 4.475263106127668e-06,
      "loss": 0.0505,
      "step": 7900
    },
    {
      "epoch": 2.345824727058129,
      "grad_norm": 25.415590286254883,
      "learning_rate": 4.376905675223764e-06,
      "loss": 0.0712,
      "step": 7950
    },
    {
      "epoch": 2.360578341693715,
      "grad_norm": 0.07372576743364334,
      "learning_rate": 4.278548244319859e-06,
      "loss": 0.0484,
      "step": 8000
    },
    {
      "epoch": 2.3753319563293007,
      "grad_norm": 0.053160857409238815,
      "learning_rate": 4.180190813415954e-06,
      "loss": 0.0584,
      "step": 8050
    },
    {
      "epoch": 2.3900855709648865,
      "grad_norm": 74.13304901123047,
      "learning_rate": 4.081833382512049e-06,
      "loss": 0.0518,
      "step": 8100
    },
    {
      "epoch": 2.4048391856004723,
      "grad_norm": 0.583559513092041,
      "learning_rate": 3.983475951608145e-06,
      "loss": 0.052,
      "step": 8150
    },
    {
      "epoch": 2.4195928002360576,
      "grad_norm": 0.10721831768751144,
      "learning_rate": 3.88511852070424e-06,
      "loss": 0.0692,
      "step": 8200
    },
    {
      "epoch": 2.4343464148716434,
      "grad_norm": 47.66019821166992,
      "learning_rate": 3.786761089800335e-06,
      "loss": 0.0497,
      "step": 8250
    },
    {
      "epoch": 2.449100029507229,
      "grad_norm": 0.15381114184856415,
      "learning_rate": 3.68840365889643e-06,
      "loss": 0.0914,
      "step": 8300
    },
    {
      "epoch": 2.463853644142815,
      "grad_norm": 0.0914602056145668,
      "learning_rate": 3.5900462279925253e-06,
      "loss": 0.045,
      "step": 8350
    },
    {
      "epoch": 2.4786072587784007,
      "grad_norm": 112.64903259277344,
      "learning_rate": 3.4916887970886203e-06,
      "loss": 0.0694,
      "step": 8400
    },
    {
      "epoch": 2.4933608734139865,
      "grad_norm": 0.1504732370376587,
      "learning_rate": 3.3933313661847157e-06,
      "loss": 0.0567,
      "step": 8450
    },
    {
      "epoch": 2.5081144880495723,
      "grad_norm": 1.6738841533660889,
      "learning_rate": 3.2949739352808107e-06,
      "loss": 0.0489,
      "step": 8500
    },
    {
      "epoch": 2.522868102685158,
      "grad_norm": 16.814905166625977,
      "learning_rate": 3.196616504376906e-06,
      "loss": 0.0642,
      "step": 8550
    },
    {
      "epoch": 2.537621717320744,
      "grad_norm": 0.34865766763687134,
      "learning_rate": 3.098259073473001e-06,
      "loss": 0.0274,
      "step": 8600
    },
    {
      "epoch": 2.552375331956329,
      "grad_norm": 4.094793796539307,
      "learning_rate": 2.999901642569096e-06,
      "loss": 0.0603,
      "step": 8650
    },
    {
      "epoch": 2.567128946591915,
      "grad_norm": 109.58271789550781,
      "learning_rate": 2.9015442116651915e-06,
      "loss": 0.0604,
      "step": 8700
    },
    {
      "epoch": 2.5818825612275007,
      "grad_norm": 12.390264511108398,
      "learning_rate": 2.8031867807612865e-06,
      "loss": 0.0746,
      "step": 8750
    },
    {
      "epoch": 2.5966361758630865,
      "grad_norm": 77.5084228515625,
      "learning_rate": 2.704829349857382e-06,
      "loss": 0.0739,
      "step": 8800
    },
    {
      "epoch": 2.6113897904986723,
      "grad_norm": 8.226426124572754,
      "learning_rate": 2.606471918953477e-06,
      "loss": 0.0326,
      "step": 8850
    },
    {
      "epoch": 2.626143405134258,
      "grad_norm": 0.1434563547372818,
      "learning_rate": 2.5081144880495724e-06,
      "loss": 0.032,
      "step": 8900
    },
    {
      "epoch": 2.6408970197698434,
      "grad_norm": 0.7828809022903442,
      "learning_rate": 2.4097570571456674e-06,
      "loss": 0.0665,
      "step": 8950
    },
    {
      "epoch": 2.655650634405429,
      "grad_norm": 0.188441202044487,
      "learning_rate": 2.311399626241763e-06,
      "loss": 0.0558,
      "step": 9000
    },
    {
      "epoch": 2.670404249041015,
      "grad_norm": 50.13199996948242,
      "learning_rate": 2.2130421953378582e-06,
      "loss": 0.0664,
      "step": 9050
    },
    {
      "epoch": 2.6851578636766007,
      "grad_norm": 0.6875573396682739,
      "learning_rate": 2.1146847644339532e-06,
      "loss": 0.0639,
      "step": 9100
    },
    {
      "epoch": 2.6999114783121865,
      "grad_norm": 0.02850819192826748,
      "learning_rate": 2.0163273335300482e-06,
      "loss": 0.0652,
      "step": 9150
    },
    {
      "epoch": 2.7146650929477723,
      "grad_norm": 148.9099884033203,
      "learning_rate": 1.9179699026261437e-06,
      "loss": 0.0504,
      "step": 9200
    },
    {
      "epoch": 2.729418707583358,
      "grad_norm": 111.78466033935547,
      "learning_rate": 1.8196124717222389e-06,
      "loss": 0.0538,
      "step": 9250
    },
    {
      "epoch": 2.744172322218944,
      "grad_norm": 5.7069993019104,
      "learning_rate": 1.721255040818334e-06,
      "loss": 0.0625,
      "step": 9300
    },
    {
      "epoch": 2.7589259368545296,
      "grad_norm": 0.6505979895591736,
      "learning_rate": 1.622897609914429e-06,
      "loss": 0.0461,
      "step": 9350
    },
    {
      "epoch": 2.773679551490115,
      "grad_norm": Infinity,
      "learning_rate": 1.5245401790105243e-06,
      "loss": 0.0634,
      "step": 9400
    },
    {
      "epoch": 2.7884331661257007,
      "grad_norm": 45.44480895996094,
      "learning_rate": 1.4281498967246975e-06,
      "loss": 0.042,
      "step": 9450
    },
    {
      "epoch": 2.8031867807612865,
      "grad_norm": 28.07804298400879,
      "learning_rate": 1.3297924658207928e-06,
      "loss": 0.051,
      "step": 9500
    },
    {
      "epoch": 2.8179403953968722,
      "grad_norm": 0.09022524207830429,
      "learning_rate": 1.2314350349168882e-06,
      "loss": 0.0503,
      "step": 9550
    },
    {
      "epoch": 2.832694010032458,
      "grad_norm": 7.852504253387451,
      "learning_rate": 1.1330776040129834e-06,
      "loss": 0.0309,
      "step": 9600
    },
    {
      "epoch": 2.847447624668044,
      "grad_norm": 0.18469096720218658,
      "learning_rate": 1.0347201731090784e-06,
      "loss": 0.0536,
      "step": 9650
    },
    {
      "epoch": 2.862201239303629,
      "grad_norm": 0.375901997089386,
      "learning_rate": 9.363627422051737e-07,
      "loss": 0.0577,
      "step": 9700
    },
    {
      "epoch": 2.876954853939215,
      "grad_norm": 0.08934126794338226,
      "learning_rate": 8.380053113012688e-07,
      "loss": 0.0297,
      "step": 9750
    },
    {
      "epoch": 2.8917084685748007,
      "grad_norm": 0.09765065461397171,
      "learning_rate": 7.39647880397364e-07,
      "loss": 0.0503,
      "step": 9800
    },
    {
      "epoch": 2.9064620832103865,
      "grad_norm": 0.2222038209438324,
      "learning_rate": 6.412904494934592e-07,
      "loss": 0.0421,
      "step": 9850
    },
    {
      "epoch": 2.9212156978459722,
      "grad_norm": 0.15233929455280304,
      "learning_rate": 5.429330185895545e-07,
      "loss": 0.0572,
      "step": 9900
    },
    {
      "epoch": 2.935969312481558,
      "grad_norm": 0.08409301936626434,
      "learning_rate": 4.4457558768564967e-07,
      "loss": 0.0296,
      "step": 9950
    },
    {
      "epoch": 2.950722927117144,
      "grad_norm": 0.675635814666748,
      "learning_rate": 3.4621815678174494e-07,
      "loss": 0.0463,
      "step": 10000
    },
    {
      "epoch": 2.9654765417527296,
      "grad_norm": 5.010300636291504,
      "learning_rate": 2.478607258778401e-07,
      "loss": 0.0508,
      "step": 10050
    },
    {
      "epoch": 2.9802301563883153,
      "grad_norm": 0.5688340663909912,
      "learning_rate": 1.4950329497393528e-07,
      "loss": 0.0468,
      "step": 10100
    },
    {
      "epoch": 2.994983771023901,
      "grad_norm": 0.07973746955394745,
      "learning_rate": 5.11458640700305e-08,
      "loss": 0.0284,
      "step": 10150
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.969091177338448,
      "eval_f1": 0.9576981322564362,
      "eval_loss": 0.16827107965946198,
      "eval_precision": 0.9608021877848678,
      "eval_recall": 0.9546140686323841,
      "eval_runtime": 66.9221,
      "eval_samples_per_second": 405.127,
      "eval_steps_per_second": 12.671,
      "step": 10167
    }
  ],
  "logging_steps": 50,
  "max_steps": 10167,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1943704310446080.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
