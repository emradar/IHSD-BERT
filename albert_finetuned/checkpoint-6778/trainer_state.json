{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 6778,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007376807317792859,
      "grad_norm": 12.337968826293945,
      "learning_rate": 1.9861316022425495e-05,
      "loss": 0.548,
      "step": 50
    },
    {
      "epoch": 0.014753614635585718,
      "grad_norm": 13.967705726623535,
      "learning_rate": 1.9716730598996756e-05,
      "loss": 0.4066,
      "step": 100
    },
    {
      "epoch": 0.02213042195337858,
      "grad_norm": 19.03507423400879,
      "learning_rate": 1.9569194452640898e-05,
      "loss": 0.4542,
      "step": 150
    },
    {
      "epoch": 0.029507229271171435,
      "grad_norm": 11.1171293258667,
      "learning_rate": 1.942165830628504e-05,
      "loss": 0.3688,
      "step": 200
    },
    {
      "epoch": 0.036884036588964296,
      "grad_norm": 18.434261322021484,
      "learning_rate": 1.9274122159929184e-05,
      "loss": 0.3617,
      "step": 250
    },
    {
      "epoch": 0.04426084390675716,
      "grad_norm": 15.461222648620605,
      "learning_rate": 1.9126586013573326e-05,
      "loss": 0.3385,
      "step": 300
    },
    {
      "epoch": 0.05163765122455002,
      "grad_norm": 13.449360847473145,
      "learning_rate": 1.897904986721747e-05,
      "loss": 0.3177,
      "step": 350
    },
    {
      "epoch": 0.05901445854234287,
      "grad_norm": 21.017671585083008,
      "learning_rate": 1.8831513720861613e-05,
      "loss": 0.3178,
      "step": 400
    },
    {
      "epoch": 0.06639126586013573,
      "grad_norm": 36.22704315185547,
      "learning_rate": 1.8683977574505758e-05,
      "loss": 0.3299,
      "step": 450
    },
    {
      "epoch": 0.07376807317792859,
      "grad_norm": 22.272438049316406,
      "learning_rate": 1.85364414281499e-05,
      "loss": 0.3583,
      "step": 500
    },
    {
      "epoch": 0.08114488049572145,
      "grad_norm": 16.60930633544922,
      "learning_rate": 1.838890528179404e-05,
      "loss": 0.3289,
      "step": 550
    },
    {
      "epoch": 0.08852168781351431,
      "grad_norm": 26.18671417236328,
      "learning_rate": 1.8241369135438183e-05,
      "loss": 0.3457,
      "step": 600
    },
    {
      "epoch": 0.09589849513130717,
      "grad_norm": 10.02774429321289,
      "learning_rate": 1.8093832989082328e-05,
      "loss": 0.3143,
      "step": 650
    },
    {
      "epoch": 0.10327530244910003,
      "grad_norm": 33.44978332519531,
      "learning_rate": 1.794629684272647e-05,
      "loss": 0.2921,
      "step": 700
    },
    {
      "epoch": 0.1106521097668929,
      "grad_norm": 20.294795989990234,
      "learning_rate": 1.779876069637061e-05,
      "loss": 0.3029,
      "step": 750
    },
    {
      "epoch": 0.11802891708468574,
      "grad_norm": 10.108233451843262,
      "learning_rate": 1.7651224550014756e-05,
      "loss": 0.2856,
      "step": 800
    },
    {
      "epoch": 0.1254057244024786,
      "grad_norm": 21.477584838867188,
      "learning_rate": 1.7503688403658898e-05,
      "loss": 0.2954,
      "step": 850
    },
    {
      "epoch": 0.13278253172027146,
      "grad_norm": 45.140769958496094,
      "learning_rate": 1.735615225730304e-05,
      "loss": 0.261,
      "step": 900
    },
    {
      "epoch": 0.14015933903806432,
      "grad_norm": 31.34942626953125,
      "learning_rate": 1.720861611094718e-05,
      "loss": 0.2818,
      "step": 950
    },
    {
      "epoch": 0.14753614635585718,
      "grad_norm": 23.328279495239258,
      "learning_rate": 1.7061079964591326e-05,
      "loss": 0.2752,
      "step": 1000
    },
    {
      "epoch": 0.15491295367365004,
      "grad_norm": 20.24951171875,
      "learning_rate": 1.6913543818235468e-05,
      "loss": 0.332,
      "step": 1050
    },
    {
      "epoch": 0.1622897609914429,
      "grad_norm": 8.586365699768066,
      "learning_rate": 1.6766007671879613e-05,
      "loss": 0.2643,
      "step": 1100
    },
    {
      "epoch": 0.16966656830923577,
      "grad_norm": 5.6287760734558105,
      "learning_rate": 1.6618471525523755e-05,
      "loss": 0.2768,
      "step": 1150
    },
    {
      "epoch": 0.17704337562702863,
      "grad_norm": 4.260448455810547,
      "learning_rate": 1.64709353791679e-05,
      "loss": 0.2886,
      "step": 1200
    },
    {
      "epoch": 0.1844201829448215,
      "grad_norm": 7.124003887176514,
      "learning_rate": 1.6326349955739157e-05,
      "loss": 0.2714,
      "step": 1250
    },
    {
      "epoch": 0.19179699026261435,
      "grad_norm": 38.735008239746094,
      "learning_rate": 1.61788138093833e-05,
      "loss": 0.2809,
      "step": 1300
    },
    {
      "epoch": 0.1991737975804072,
      "grad_norm": 18.595767974853516,
      "learning_rate": 1.6031277663027444e-05,
      "loss": 0.2989,
      "step": 1350
    },
    {
      "epoch": 0.20655060489820007,
      "grad_norm": 18.589059829711914,
      "learning_rate": 1.5883741516671586e-05,
      "loss": 0.3049,
      "step": 1400
    },
    {
      "epoch": 0.21392741221599293,
      "grad_norm": 17.99054527282715,
      "learning_rate": 1.573620537031573e-05,
      "loss": 0.2758,
      "step": 1450
    },
    {
      "epoch": 0.2213042195337858,
      "grad_norm": 29.076274871826172,
      "learning_rate": 1.5588669223959872e-05,
      "loss": 0.2802,
      "step": 1500
    },
    {
      "epoch": 0.22868102685157865,
      "grad_norm": 17.367307662963867,
      "learning_rate": 1.5441133077604014e-05,
      "loss": 0.2994,
      "step": 1550
    },
    {
      "epoch": 0.23605783416937148,
      "grad_norm": 14.968669891357422,
      "learning_rate": 1.529359693124816e-05,
      "loss": 0.2888,
      "step": 1600
    },
    {
      "epoch": 0.24343464148716434,
      "grad_norm": 18.73406219482422,
      "learning_rate": 1.51460607848923e-05,
      "loss": 0.2597,
      "step": 1650
    },
    {
      "epoch": 0.2508114488049572,
      "grad_norm": 7.858233451843262,
      "learning_rate": 1.4998524638536442e-05,
      "loss": 0.2768,
      "step": 1700
    },
    {
      "epoch": 0.2581882561227501,
      "grad_norm": 5.755744934082031,
      "learning_rate": 1.4850988492180584e-05,
      "loss": 0.2855,
      "step": 1750
    },
    {
      "epoch": 0.2655650634405429,
      "grad_norm": 20.31941795349121,
      "learning_rate": 1.4703452345824729e-05,
      "loss": 0.3098,
      "step": 1800
    },
    {
      "epoch": 0.2729418707583358,
      "grad_norm": 19.21998405456543,
      "learning_rate": 1.455591619946887e-05,
      "loss": 0.2732,
      "step": 1850
    },
    {
      "epoch": 0.28031867807612865,
      "grad_norm": 24.200735092163086,
      "learning_rate": 1.4408380053113014e-05,
      "loss": 0.2623,
      "step": 1900
    },
    {
      "epoch": 0.28769548539392154,
      "grad_norm": 11.679715156555176,
      "learning_rate": 1.4260843906757156e-05,
      "loss": 0.2567,
      "step": 1950
    },
    {
      "epoch": 0.29507229271171437,
      "grad_norm": 13.640704154968262,
      "learning_rate": 1.41133077604013e-05,
      "loss": 0.3082,
      "step": 2000
    },
    {
      "epoch": 0.30244910002950726,
      "grad_norm": 27.202911376953125,
      "learning_rate": 1.3965771614045442e-05,
      "loss": 0.2226,
      "step": 2050
    },
    {
      "epoch": 0.3098259073473001,
      "grad_norm": 10.228604316711426,
      "learning_rate": 1.3818235467689584e-05,
      "loss": 0.2762,
      "step": 2100
    },
    {
      "epoch": 0.3172027146650929,
      "grad_norm": 48.73519515991211,
      "learning_rate": 1.3670699321333727e-05,
      "loss": 0.2884,
      "step": 2150
    },
    {
      "epoch": 0.3245795219828858,
      "grad_norm": 15.624505043029785,
      "learning_rate": 1.352316317497787e-05,
      "loss": 0.2673,
      "step": 2200
    },
    {
      "epoch": 0.33195632930067864,
      "grad_norm": 9.287976264953613,
      "learning_rate": 1.3375627028622014e-05,
      "loss": 0.2744,
      "step": 2250
    },
    {
      "epoch": 0.33933313661847153,
      "grad_norm": 10.561844825744629,
      "learning_rate": 1.3228090882266156e-05,
      "loss": 0.2453,
      "step": 2300
    },
    {
      "epoch": 0.34670994393626436,
      "grad_norm": 13.785481452941895,
      "learning_rate": 1.3080554735910297e-05,
      "loss": 0.2764,
      "step": 2350
    },
    {
      "epoch": 0.35408675125405725,
      "grad_norm": 9.175721168518066,
      "learning_rate": 1.2933018589554442e-05,
      "loss": 0.245,
      "step": 2400
    },
    {
      "epoch": 0.3614635585718501,
      "grad_norm": 12.592459678649902,
      "learning_rate": 1.2785482443198584e-05,
      "loss": 0.2953,
      "step": 2450
    },
    {
      "epoch": 0.368840365889643,
      "grad_norm": 6.354276180267334,
      "learning_rate": 1.2637946296842727e-05,
      "loss": 0.2766,
      "step": 2500
    },
    {
      "epoch": 0.3762171732074358,
      "grad_norm": 14.487339973449707,
      "learning_rate": 1.249041015048687e-05,
      "loss": 0.2772,
      "step": 2550
    },
    {
      "epoch": 0.3835939805252287,
      "grad_norm": 27.834148406982422,
      "learning_rate": 1.2342874004131014e-05,
      "loss": 0.2493,
      "step": 2600
    },
    {
      "epoch": 0.39097078784302153,
      "grad_norm": 13.11807632446289,
      "learning_rate": 1.2195337857775156e-05,
      "loss": 0.2894,
      "step": 2650
    },
    {
      "epoch": 0.3983475951608144,
      "grad_norm": 20.776229858398438,
      "learning_rate": 1.2047801711419297e-05,
      "loss": 0.2435,
      "step": 2700
    },
    {
      "epoch": 0.40572440247860725,
      "grad_norm": 12.606809616088867,
      "learning_rate": 1.1900265565063442e-05,
      "loss": 0.2721,
      "step": 2750
    },
    {
      "epoch": 0.41310120979640014,
      "grad_norm": 18.255512237548828,
      "learning_rate": 1.1752729418707584e-05,
      "loss": 0.2447,
      "step": 2800
    },
    {
      "epoch": 0.42047801711419297,
      "grad_norm": 11.977733612060547,
      "learning_rate": 1.1605193272351727e-05,
      "loss": 0.2384,
      "step": 2850
    },
    {
      "epoch": 0.42785482443198586,
      "grad_norm": 8.806693077087402,
      "learning_rate": 1.1457657125995869e-05,
      "loss": 0.2464,
      "step": 2900
    },
    {
      "epoch": 0.4352316317497787,
      "grad_norm": 16.749502182006836,
      "learning_rate": 1.1310120979640014e-05,
      "loss": 0.2633,
      "step": 2950
    },
    {
      "epoch": 0.4426084390675716,
      "grad_norm": 8.20709228515625,
      "learning_rate": 1.1162584833284156e-05,
      "loss": 0.2774,
      "step": 3000
    },
    {
      "epoch": 0.4499852463853644,
      "grad_norm": 9.535345077514648,
      "learning_rate": 1.1015048686928297e-05,
      "loss": 0.231,
      "step": 3050
    },
    {
      "epoch": 0.4573620537031573,
      "grad_norm": 14.74157428741455,
      "learning_rate": 1.086751254057244e-05,
      "loss": 0.2585,
      "step": 3100
    },
    {
      "epoch": 0.46473886102095013,
      "grad_norm": 30.95235824584961,
      "learning_rate": 1.0719976394216584e-05,
      "loss": 0.2844,
      "step": 3150
    },
    {
      "epoch": 0.47211566833874297,
      "grad_norm": 17.446569442749023,
      "learning_rate": 1.0572440247860728e-05,
      "loss": 0.2486,
      "step": 3200
    },
    {
      "epoch": 0.47949247565653585,
      "grad_norm": 27.530319213867188,
      "learning_rate": 1.042490410150487e-05,
      "loss": 0.2466,
      "step": 3250
    },
    {
      "epoch": 0.4868692829743287,
      "grad_norm": 9.046646118164062,
      "learning_rate": 1.0277367955149011e-05,
      "loss": 0.2518,
      "step": 3300
    },
    {
      "epoch": 0.4942460902921216,
      "grad_norm": 16.098756790161133,
      "learning_rate": 1.0129831808793156e-05,
      "loss": 0.2355,
      "step": 3350
    },
    {
      "epoch": 0.5016228976099144,
      "grad_norm": 10.280245780944824,
      "learning_rate": 9.982295662437298e-06,
      "loss": 0.2518,
      "step": 3400
    },
    {
      "epoch": 0.5089997049277073,
      "grad_norm": 29.52805519104004,
      "learning_rate": 9.834759516081441e-06,
      "loss": 0.2594,
      "step": 3450
    },
    {
      "epoch": 0.5163765122455002,
      "grad_norm": 31.77566909790039,
      "learning_rate": 9.687223369725584e-06,
      "loss": 0.2215,
      "step": 3500
    },
    {
      "epoch": 0.523753319563293,
      "grad_norm": 22.124807357788086,
      "learning_rate": 9.539687223369728e-06,
      "loss": 0.2335,
      "step": 3550
    },
    {
      "epoch": 0.5311301268810859,
      "grad_norm": 15.564515113830566,
      "learning_rate": 9.39215107701387e-06,
      "loss": 0.2561,
      "step": 3600
    },
    {
      "epoch": 0.5385069341988787,
      "grad_norm": 11.973548889160156,
      "learning_rate": 9.244614930658013e-06,
      "loss": 0.2463,
      "step": 3650
    },
    {
      "epoch": 0.5458837415166716,
      "grad_norm": 7.770747184753418,
      "learning_rate": 9.097078784302154e-06,
      "loss": 0.2417,
      "step": 3700
    },
    {
      "epoch": 0.5532605488344644,
      "grad_norm": 6.5297160148620605,
      "learning_rate": 8.949542637946298e-06,
      "loss": 0.2519,
      "step": 3750
    },
    {
      "epoch": 0.5606373561522573,
      "grad_norm": 12.261504173278809,
      "learning_rate": 8.802006491590441e-06,
      "loss": 0.2631,
      "step": 3800
    },
    {
      "epoch": 0.5680141634700502,
      "grad_norm": 21.841552734375,
      "learning_rate": 8.654470345234584e-06,
      "loss": 0.2366,
      "step": 3850
    },
    {
      "epoch": 0.5753909707878431,
      "grad_norm": 23.553476333618164,
      "learning_rate": 8.506934198878726e-06,
      "loss": 0.2437,
      "step": 3900
    },
    {
      "epoch": 0.5827677781056358,
      "grad_norm": 16.158241271972656,
      "learning_rate": 8.35939805252287e-06,
      "loss": 0.2466,
      "step": 3950
    },
    {
      "epoch": 0.5901445854234287,
      "grad_norm": 9.707541465759277,
      "learning_rate": 8.211861906167011e-06,
      "loss": 0.234,
      "step": 4000
    },
    {
      "epoch": 0.5975213927412216,
      "grad_norm": 11.988800048828125,
      "learning_rate": 8.064325759811154e-06,
      "loss": 0.2085,
      "step": 4050
    },
    {
      "epoch": 0.6048982000590145,
      "grad_norm": 5.382806777954102,
      "learning_rate": 7.916789613455298e-06,
      "loss": 0.2544,
      "step": 4100
    },
    {
      "epoch": 0.6122750073768073,
      "grad_norm": 25.478975296020508,
      "learning_rate": 7.769253467099441e-06,
      "loss": 0.211,
      "step": 4150
    },
    {
      "epoch": 0.6196518146946002,
      "grad_norm": 15.680798530578613,
      "learning_rate": 7.621717320743583e-06,
      "loss": 0.2182,
      "step": 4200
    },
    {
      "epoch": 0.6270286220123931,
      "grad_norm": 11.888014793395996,
      "learning_rate": 7.474181174387726e-06,
      "loss": 0.2475,
      "step": 4250
    },
    {
      "epoch": 0.6344054293301858,
      "grad_norm": 27.489580154418945,
      "learning_rate": 7.326645028031868e-06,
      "loss": 0.236,
      "step": 4300
    },
    {
      "epoch": 0.6417822366479787,
      "grad_norm": 16.114187240600586,
      "learning_rate": 7.179108881676011e-06,
      "loss": 0.2269,
      "step": 4350
    },
    {
      "epoch": 0.6491590439657716,
      "grad_norm": 13.343111038208008,
      "learning_rate": 7.0315727353201535e-06,
      "loss": 0.2278,
      "step": 4400
    },
    {
      "epoch": 0.6565358512835645,
      "grad_norm": 14.922592163085938,
      "learning_rate": 6.884036588964297e-06,
      "loss": 0.2334,
      "step": 4450
    },
    {
      "epoch": 0.6639126586013573,
      "grad_norm": 20.302791595458984,
      "learning_rate": 6.73650044260844e-06,
      "loss": 0.1977,
      "step": 4500
    },
    {
      "epoch": 0.6712894659191502,
      "grad_norm": 25.185075759887695,
      "learning_rate": 6.588964296252583e-06,
      "loss": 0.1925,
      "step": 4550
    },
    {
      "epoch": 0.6786662732369431,
      "grad_norm": 13.247838973999023,
      "learning_rate": 6.441428149896726e-06,
      "loss": 0.2573,
      "step": 4600
    },
    {
      "epoch": 0.686043080554736,
      "grad_norm": 16.743024826049805,
      "learning_rate": 6.293892003540868e-06,
      "loss": 0.1742,
      "step": 4650
    },
    {
      "epoch": 0.6934198878725287,
      "grad_norm": 38.520511627197266,
      "learning_rate": 6.146355857185011e-06,
      "loss": 0.2067,
      "step": 4700
    },
    {
      "epoch": 0.7007966951903216,
      "grad_norm": 15.407919883728027,
      "learning_rate": 5.9988197108291535e-06,
      "loss": 0.2275,
      "step": 4750
    },
    {
      "epoch": 0.7081735025081145,
      "grad_norm": 4.368709564208984,
      "learning_rate": 5.851283564473297e-06,
      "loss": 0.2105,
      "step": 4800
    },
    {
      "epoch": 0.7155503098259074,
      "grad_norm": 0.7092146873474121,
      "learning_rate": 5.703747418117439e-06,
      "loss": 0.1925,
      "step": 4850
    },
    {
      "epoch": 0.7229271171437002,
      "grad_norm": 52.02390670776367,
      "learning_rate": 5.556211271761583e-06,
      "loss": 0.2512,
      "step": 4900
    },
    {
      "epoch": 0.7303039244614931,
      "grad_norm": 0.7379040718078613,
      "learning_rate": 5.408675125405724e-06,
      "loss": 0.1989,
      "step": 4950
    },
    {
      "epoch": 0.737680731779286,
      "grad_norm": 15.035908699035645,
      "learning_rate": 5.261138979049868e-06,
      "loss": 0.2043,
      "step": 5000
    },
    {
      "epoch": 0.7450575390970788,
      "grad_norm": 21.627744674682617,
      "learning_rate": 5.11360283269401e-06,
      "loss": 0.2174,
      "step": 5050
    },
    {
      "epoch": 0.7524343464148716,
      "grad_norm": 9.925052642822266,
      "learning_rate": 4.966066686338154e-06,
      "loss": 0.211,
      "step": 5100
    },
    {
      "epoch": 0.7598111537326645,
      "grad_norm": 2.364935874938965,
      "learning_rate": 4.818530539982296e-06,
      "loss": 0.2193,
      "step": 5150
    },
    {
      "epoch": 0.7671879610504574,
      "grad_norm": 13.458019256591797,
      "learning_rate": 4.6709943936264394e-06,
      "loss": 0.2124,
      "step": 5200
    },
    {
      "epoch": 0.7745647683682502,
      "grad_norm": 13.675214767456055,
      "learning_rate": 4.523458247270582e-06,
      "loss": 0.243,
      "step": 5250
    },
    {
      "epoch": 0.7819415756860431,
      "grad_norm": 34.96629333496094,
      "learning_rate": 4.3759221009147245e-06,
      "loss": 0.1853,
      "step": 5300
    },
    {
      "epoch": 0.7893183830038359,
      "grad_norm": 21.160879135131836,
      "learning_rate": 4.228385954558867e-06,
      "loss": 0.2431,
      "step": 5350
    },
    {
      "epoch": 0.7966951903216288,
      "grad_norm": 27.76220703125,
      "learning_rate": 4.08084980820301e-06,
      "loss": 0.2167,
      "step": 5400
    },
    {
      "epoch": 0.8040719976394216,
      "grad_norm": 21.082975387573242,
      "learning_rate": 3.933313661847153e-06,
      "loss": 0.1826,
      "step": 5450
    },
    {
      "epoch": 0.8114488049572145,
      "grad_norm": 12.417655944824219,
      "learning_rate": 3.7857775154912957e-06,
      "loss": 0.1967,
      "step": 5500
    },
    {
      "epoch": 0.8188256122750074,
      "grad_norm": 13.493586540222168,
      "learning_rate": 3.6382413691354387e-06,
      "loss": 0.2125,
      "step": 5550
    },
    {
      "epoch": 0.8262024195928003,
      "grad_norm": 28.061580657958984,
      "learning_rate": 3.490705222779581e-06,
      "loss": 0.1957,
      "step": 5600
    },
    {
      "epoch": 0.833579226910593,
      "grad_norm": 16.482431411743164,
      "learning_rate": 3.346119799350841e-06,
      "loss": 0.2107,
      "step": 5650
    },
    {
      "epoch": 0.8409560342283859,
      "grad_norm": 4.979456424713135,
      "learning_rate": 3.1985836529949844e-06,
      "loss": 0.2157,
      "step": 5700
    },
    {
      "epoch": 0.8483328415461788,
      "grad_norm": 12.6471529006958,
      "learning_rate": 3.0510475066391273e-06,
      "loss": 0.2151,
      "step": 5750
    },
    {
      "epoch": 0.8557096488639717,
      "grad_norm": 40.52971649169922,
      "learning_rate": 2.9035113602832698e-06,
      "loss": 0.185,
      "step": 5800
    },
    {
      "epoch": 0.8630864561817645,
      "grad_norm": 18.688411712646484,
      "learning_rate": 2.7559752139274127e-06,
      "loss": 0.2147,
      "step": 5850
    },
    {
      "epoch": 0.8704632634995574,
      "grad_norm": 21.94818878173828,
      "learning_rate": 2.608439067571555e-06,
      "loss": 0.2308,
      "step": 5900
    },
    {
      "epoch": 0.8778400708173503,
      "grad_norm": 31.13027000427246,
      "learning_rate": 2.460902921215698e-06,
      "loss": 0.1919,
      "step": 5950
    },
    {
      "epoch": 0.8852168781351432,
      "grad_norm": 25.966917037963867,
      "learning_rate": 2.313366774859841e-06,
      "loss": 0.199,
      "step": 6000
    },
    {
      "epoch": 0.8925936854529359,
      "grad_norm": 4.869497299194336,
      "learning_rate": 2.1658306285039836e-06,
      "loss": 0.1623,
      "step": 6050
    },
    {
      "epoch": 0.8999704927707288,
      "grad_norm": 20.67426109313965,
      "learning_rate": 2.0182944821481265e-06,
      "loss": 0.2182,
      "step": 6100
    },
    {
      "epoch": 0.9073473000885217,
      "grad_norm": 16.106834411621094,
      "learning_rate": 1.8707583357922692e-06,
      "loss": 0.2315,
      "step": 6150
    },
    {
      "epoch": 0.9147241074063146,
      "grad_norm": 27.419178009033203,
      "learning_rate": 1.7232221894364121e-06,
      "loss": 0.2086,
      "step": 6200
    },
    {
      "epoch": 0.9221009147241074,
      "grad_norm": 4.9875407218933105,
      "learning_rate": 1.5756860430805548e-06,
      "loss": 0.1863,
      "step": 6250
    },
    {
      "epoch": 0.9294777220419003,
      "grad_norm": 39.41266632080078,
      "learning_rate": 1.4281498967246975e-06,
      "loss": 0.2171,
      "step": 6300
    },
    {
      "epoch": 0.9368545293596932,
      "grad_norm": 5.8171162605285645,
      "learning_rate": 1.2806137503688405e-06,
      "loss": 0.1955,
      "step": 6350
    },
    {
      "epoch": 0.9442313366774859,
      "grad_norm": 44.5320930480957,
      "learning_rate": 1.1330776040129834e-06,
      "loss": 0.1978,
      "step": 6400
    },
    {
      "epoch": 0.9516081439952788,
      "grad_norm": 10.142857551574707,
      "learning_rate": 9.855414576571261e-07,
      "loss": 0.1765,
      "step": 6450
    },
    {
      "epoch": 0.9589849513130717,
      "grad_norm": 27.305755615234375,
      "learning_rate": 8.380053113012688e-07,
      "loss": 0.1872,
      "step": 6500
    },
    {
      "epoch": 0.9663617586308646,
      "grad_norm": 19.572065353393555,
      "learning_rate": 6.904691649454116e-07,
      "loss": 0.1559,
      "step": 6550
    },
    {
      "epoch": 0.9737385659486574,
      "grad_norm": 27.815942764282227,
      "learning_rate": 5.429330185895545e-07,
      "loss": 0.2392,
      "step": 6600
    },
    {
      "epoch": 0.9811153732664503,
      "grad_norm": 10.639201164245605,
      "learning_rate": 3.953968722336973e-07,
      "loss": 0.1759,
      "step": 6650
    },
    {
      "epoch": 0.9884921805842432,
      "grad_norm": 13.815352439880371,
      "learning_rate": 2.478607258778401e-07,
      "loss": 0.1773,
      "step": 6700
    },
    {
      "epoch": 0.995868987902036,
      "grad_norm": 32.912559509277344,
      "learning_rate": 1.0032457952198289e-07,
      "loss": 0.2045,
      "step": 6750
    }
  ],
  "logging_steps": 50,
  "max_steps": 6778,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 647901436815360.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
